\newacronym{ctan}{CTAN}{Comprehensive TeX Archive Network}
\newacronym{faq}{FAQ}{Frequently Asked Questions}
\newacronym{pdf}{PDF}{Portable Document Format}
\newacronym{svn}{SVN}{Subversion}
\newacronym{wysiwyg}{WYSIWYG}{What You See Is What You Get}

\newglossaryentry{texteditor}
{
	name={editor},
	description={A text editor is a type of program used for editing plain text files.}
}

\chapter{Abstract}

This is where the first chapter begins...

\chapter{Related Publications}

This is where the first chapter begins...

\chapter{Overview}

%\textbf{Importance of visualisation in the physiology}
%Physiology describes how livings organism work, and it spans across multiple scientific fields.
%It is therefore important to be able to communicate scientific advances efficiently between experts with various scientific background.
%Additionally, there is also a growing interest from the general audience to understand how their own body function.
%Explaining such complex processes is usually very challenging without a supporting illustration.
%Although some illustrators are still doing hand-made illustrations, many of them are using tools inspired from movie production to accelerate their work.
%Despite that, modeling a single scenario is still very time consuming (gathering data and realization).
%Moreover, illustrations are usually static, (still images and movies) and do not offer much interactivity.

%Printed illustrations have the clear advantage to be easily accessible by the viewer, via a school textooks, scientific magazines, encyclopedia, or simply via the web. 
%To being with this ambitious enterprise it is necessary to starting studying how processes work on the atomic level, the smallest level which we  understand to this day.
%It also exists different types of supports for visual communication other than still images, such as animated movies (animated and non-interactive) and educational games (animated and interactive).
%Due to the popularity of digital effects used in the movie industry over the last decades, 3D animation packages and online training became widely available thus popularizing the use of these tools by scientific illustrators.
%The storytelling is a key element of an illustration as it is responsible of conveying the core message.
%Animated content is very powerful in illustration because it efficiently engages the viewer into the story (stupid comparison of people preferring movies to books).
%Due to the , 3D animation packages and online training became widely available thus popularizing the use of these tools by scientific illustrators.
%which became widely available thanks to the popularity of digital effects used in the movie industry over the last decades
%In order to understand how we work we must first understand the complete cascade of events down from atomic level and up to microscopic and macroscopic levels.

\section{Introduction}

\textbf{Importance of Visualisation in Biology} \\
Biochemistry lies at the root of complex biological systems that describe the machinery of life, and in order to understand how we work we must first understand the complete cascade of events that is taking place at the atomic level.
Because biological systems spans several scales and scientific fields, such as biology, chemistry, mathematics, or medicine, it is crucial to communicate advances in biochemistry efficiently between experts with various scientific background.
Moreover, there is also a growing interest from the general audience to understand how their living organisms work.
Visual communication is undeniably an efficient way to educate a non-expert audience about the functioning of physiological processes.
A quick glance at physiological textbooks is enough to realize that they would be close to useless without any illustrations.
Illustrations, such as the ones made by David Goodsell, are often used to illustrate such textbooks.
The illustrator likes to depict entire sceneries on the mesoscale levels, such as ...(figure X) that would be impossible to observe otherwise in such detail using current optical instruments.
His paintings rightfully balance scientific accuracy and clarity, which makes them very popular because they are accessible to a large audience. 
The realization of such illustrations, however, is very laborious and also demands highly skilled individuals.
The first step of the creation process consists of gathering knowledge from the scientific literature in order to thoroughly understand the process that is to be depicted.
This task demands a strong understanding of biology as scientific articles are intended to be read by experts and peers.
Based on this knowledge, the illustrator will decide how to compose the scene, i.e., which macromolecular structures should be present, where should they be located, in which quantities, and what behaviour should they exhibit.
The second step of the creation process is the drawing. 
It is important not to confuse the work of a scientific illustrator with the work of an artist.
Although they both aim at conveying a message or an idea, the artist has the freedom to hide his message behind an abstraction curtain in order to challenge the viewer.
On the contrary, an illustrator has to convey a message as clearly as possible in order to expose scientific concepts to an uninformed audience.
This concretely means that the illustrator is bound to a set of logical guidelines in terms of composition, lighting, color-coding or storytelling.

While some illustrators prefer working with paper and pencil or 2D composition software such as Photoshop, the new generation of illustrators grew with 3D rendering and animation packages such as Maya, Cinema4D or Blender, made mainstream by the popularization of digital effects in the movie industry.
The use of such computer aided design tools greatly facilitates the drawing operation of three dimensional data.
Perspective and lighting effects, for instance, are automatically handled by the software, thus leaving artists more time to work on other aspects such as material design, composition, or post-processing.
Since less time is spent working on single images it is also less cumbersome to produce animated stories.
Consequently, 3D animation  became an increasingly popular means of visual communication to depict the machinery of life, as it is a great way to engage the viewer into a storyline.
One notorious animated educational material is "The Inner Life of the Cell" realized in 2008 by the XVIVO medical illustration studio and appointed by Harvard University.
This short animated video beautifully depicts in few sequences the logical cascade of events that describe complex biochemical processes of a living cell.
The structures of the different actors are based on real structural information available from public databases and their behaviour based on the most recent knowledge of cell biology.
Furthermore, environments surrounding each event is also accurately depicted to provide important information about location and scale.
This masterpiece of scientific animation took the whole team of experts 14 month to produce, which is a good average production time for a 5 to 10 minutes educational material of this quality.
Unfortunately, on top of being time consuming, the production of such films is also very costly, which somehow limits the accessibility and availability of such visualization.

%Over the last years, the net revenues of the computer game industry have largely outperformed those of the movie industry, which was not the case a few years ago.
%This trend clearly indicates the growing interest of the public in interactive entertainment and  storytelling. 
%Moreover, the recent emergence of a new generation of virtual and augmented reality hardware such as the Occulus Rift, HTC Vive, Microsoft Hololens, are now paving the way towards the next generation of computer games which promise to be even more immersive, realistic and engaging.
%Given the raising interest of the general audience in this type of interactive experience we can imagine that this could be hugely effective for edutainment and scientific dissemination of cell biology.
%By embedding the subject into the presented content, he becomes an actor of the virtual world and his attention naturally increases. 

%\textbf{Here break the read thread between games, and introduce the idea of entirely virtual biological systems.}

Another type of media which has a great potential for educational purposes is interactive applications.
Compared to movies, interactive titles, such as computer games, are able to keep the player engaged with educational content using the traditional reward system present in many computer games.
Immune Attack[] or Sim Cell[] are two famous examples of edutainment titles whose goal is to reveal the functioning of living cells through accomplishment of actions that are part of physiological processes.
Promising new VR devices have also emerged over the last years, and are now paving the way for more exciting and engaging user experiences that could have a great educational outreach.
However, the production of high quality interactive content, similarly to animated films, is also a lengthy and costly enterprise, as technicians and programming experts are also needed in addition to the team.
Interactive applications may also have an educational purpose without necessarily introducing gameplay mechanisms or score-based rewards. 
A good example is interactive maps applications, such as Google Earth[].
Unlike static maps, these applications enable on-demand access to specific information.
Through a set of 2D interactions such as zoom, rotate and pan, or 3D interactions such as tilt, the user is free to navigate to whichever part of earth that he deems interesting.
It also features multiple zoom levels from planets down to the size of building, houses or even cars.
Another strong advantage of the platform is crowd-based collaboration.
Three dimensional data obtained from scans of entire cities for instance can be provided by the municipalities and added to the platform for in-depth city architecture exploration.
Finally, the platform is not only bound to static representation of earth, dynamic data such as traffic or meteorology provided by third party applications can also be plugged and included to the platform.
The final outcome is a system that enables omniscient and three dimensional observation of the planet and its dynamics based on available data.
The educational outreach of this software is undeniable as it transcend all types of media previously used and provides unconstrained access to multiple types of information at once. 

To our knowledge, the concept of reproducing an observable virtual environment as such, has not yet been transposed to the level of an entire cell.
In order to achieve this enterprise one would need access to important data such as the three dimensional structures of macromolecules and greater ensembles that form the compartments and various organelles of the cells.
As cells carry multiple functions expressed in biological systems, reaction networks between micro and macromolecules, as well as dynamic data, such as molecular reactions and migration patterns also would be needed to digitally reproduce a truly observable living cell.
Fortunately, a large amount of biological knowledge is publicly available via online databases.
The Protein Data Bank[], for instance, is a project that aims at regrouping every known protein structures in large public data base.
Ecocyc[], is another project that aim at gathering extensive procedural descriptions of the biological systems that are ongoing in the E. Coli bacterium.
Based on these descriptions, biologists have managed to simulate processes of the entire bacterium at once on a super-computer and have also made the results available.
Similarly to satellite data, or traffic data in Google Earth, the data present in these databases are steadily updated with most recent scientific knowledge by a large crowd of researchers, for as long as the projects are maintained.
Despite the large quantity of data available, there is yet no solution that could generate a comprehensible digital cell based on this data, and that would be both dynamic and multiscale.
As the production of animated and interactive educational content is often prohibitive, we envision that such interactive platform would be a great mean to keep layman audiences and multidisciplinary experts informed about the latest knowledge of cell biology.

%\textbf{Here break the read thread between games, and introduce the idea of entirely virtual biological systems.}
%
%analogy to Google Earth (Virtual Earth)
%, not static maps, on demand access to specific inforation.
%Not a game, not movies, something new different concept.
%Google maps 
%
%Crowd based participation on structures...
%Structures vs dynamics of traffic for instance.
%Increasing incorporation of dynamics phenomena.
%Unconstrained access,
%
%What is needed for applying same concept to cell level ??
%What are structures, envrionements, actors, protein energy organelles reaction networks.
%
%(A large amount) these information is already available (PDB, cellpack, computational models)
%And is also steadily updated.
%
%(http://ecocyc.org/) Try to gather multiple of information in one place (Wiki)
%\textit{EcoCyc is a scientific database for the bacterium Escherichia coli K-12 MG1655. The EcoCyc project performs literature-based curation of the entire genome, and of transcriptional regulation, transporters, and metabolic pathways. }
%
%The data ----> google earth



%Another type of media which has a great potential for educational purposes is computer games.
%Immune Attack[] or Sim Cell[] are two famous examples of edutainment titles whose goal is to reveal the functioning of living cells through accomplishment of actions that are part of physiological processes.
%These titles are based on the traditional reward system present in many computer games and that ensures to keep the player engaged with educational content.
%The motivation of a player, however, does not always have to be solely driven by the high-scores.
%We can observe a recent trend among AAA game titles towards interactive storytelling rather than pure gameplay.
%Those titles usually feature cinematic sequences, interleaved between interactive sessions.
%The resulting user experience then blends animation and interaction, and the player's motivation is thus driven by his curiosity to unravel the storyline rather than high-scores.
%We envision to translate this concept to dissemination of sciences in order to produce more engaging user experiences that would raise awareness about cell biology.
%Interactive rendering would also enable new types of action for user-driver exploration that would not be possible otherwise with movies, such as camera navigation, selective visibility of certain elements to reveal important hidden structures, or interactive change of biochemical properties to modify the course of the scenario.
%Additionally, the recent emergence of highly capable virtual reality headsets promises the next generation of interactive experiences to be even more immersive and engaging.
%This could encourage even more people to explore and interact with virtual educational content.
%
%The production of high quality interactive content, however, is often more constrained than the production of offline animations.
%Indeed, due to fast framerates needed in computer games (20 to 60 fps, and even more for VR) it is difficult to interactively render entire complex environments that we may see in movies, which could affect the overall educational impact. 
%Additionally, the creation team also requires more people, e.g. computer programmers, which could increase the production costs and times compared to movies.
%Given that the creation of a high quality explanatory videos about cell biology is already a very lengthy and costly enterprise, it is clear that new tools and technologies would have be developed to enable the creation of next generation of interactive user-experiences that would keep audiences informed about cell biology. 
%
%Firstly, it is important to improve the real-time rendering capabilities of interactive content creation tools, in order to quickly display large and complex structures on par with those seen in animated movies.
%Secondly, is it also crucial to streamline the content creation process in order to reduce production times and costs.
%Computational biology generates data which contains valuable information about the structures of macromolecular elements and ensembles which compose molecular landscapes.
%It also comprise procedural descriptions of dynamic biological systems, obtained via computerised simulations.
%Our idea is to combine these two aspects to virtually reproduce an observable dynamic biological system in three dimensions.
%Animations would then be automatically generated by scientific data, thus saving illustrators countless hours of manual composition and animation.
%Ultimately, we envision this concept to lead to the popularization of digital and educational material and thus to improve visual communication to layman audiences and across scientific disciples.


%In biology the cost of wet lab experiments is significantly higher than the cost of computer-based simulations.%
%Such simulation have a great value because they provide important insight about the functioning of a system. %
%Over the last years the use of computer-based simulation have significantly increase in biology.
%\textit{The goal of a model is to approximate a given process, a complete and accurate model might simply too complex to describe of to simulate, also some aspects may sometimes be unknown}%
%\textit{Isolate a single part of the entire machinery to easily study its mechanism.}%
%These experiments are widely criticized because often deemed too approximative due to human knowledge or computational limitations.

\section{Background and Related Work}

\textbf{Computational Biology to Assist Scientific Illustration}\\
In biochemistry, it exists two distinct experimental protocols, respectively called dry and wet laboratories.
Wet laboratories are where chemical agents are physically manipulated and then observed.
Dry laboratories are where computational or mathematical methods are employed for the modelling and analysis of biochemical processes. 
Over the last decades, \textit{in-silico} (dry laboratories) experiments have significantly increased due to the development of new software and the decreasing costs of super computers.
%Due to computational or human limitations, it may be often impractical to accurately simulated a given process in its entirety.
Despite being often criticized for being too approximative, dry laboratory experiments represent a valuable source of information for researchers nonetheless.
In 2013 Martin Karplus, Michael Levitt and Arieh Warshel were awarded the Nobel prize in Chemistry for their work of theoretical modelling for complex chemical system.
Their work highlight the importance of theoretical modelling as a tool to complement experimental techniques as wet-lab experiments are usually complex and expensive to conduct.
The analysis of theoretical modeling brings researchers the necessary guidance to formulate new hypothesis which can be later on verified in wet laboratories, this saving the time and money needed to run too many wet lab experiments.
As a result of the increasing popularity of dry lab experiments, a significant amount of data has already been gathered and produced.
Data is often stored in digital format and can shared to other peers via online databases.
Structural biology and Systems biology are branches or molecular biology that both heavily rely on computational method.
Structural biology informs us about how things look, i.e., what is the atomic structure of a protein, while systems biology informs use about how things work, i.e., how micro and macromolecular interacts and to form a given physiological process.

%\section{Related Work}
%
%Our goal is to improve visual communication of molecular biology, and ultimately to promote interactive showcasing as a standard media for educating the masses about biology.
%Valuable data from computation biology is constantly produced by experts and is often publicly available. 
%It contains thorough description about how things look (structures) and how things work (processes), and we intend to make extensive use of this data to enable the next generation of scientific illustration.
%The visualization literature already comprises a few work that are going in a similar direction and we will distinguish between the related work related to structural visualization in the first section and follow-up with related work about visualization of biochemical processes.

\subsection{Visualization of Biological Structures}

Structural biology is concerned by the structure of biological macromolecules (proteins and nucleic acids), and the relationship between molecular structure and function.
Data acquisition methods such as x-ray crystallography are traditionally used to read in details the atomic structure of proteins, i.e, the positions or atoms, their type and the type of bonds between them.
Acquired atomic structures are often stored in digital files and shared via public data bases such as the Protein Data Bank[] to facilitate collaboration among biologists.
This information is then processed to decrypt underlying important structural information and also used to run molecular dynamics (MD) simulations, which aims at reproducing atomic interactions and forces to observe the actual behaviour of macromolecules over time.
Visualization is an important component of this discipline because atoms are arranged and assembled in 3 dimensional space and therefore a visual representation is often required.
Biologists developed several types of representation to illustrate molecular structures, and they are also supported by mainstream visualization packages such as VMD[] or PyMol[].
The simplest representation is the sticks model, where each bonds are represented as a line, and color coding is used to indicate the atom type at the line extremities or joints.
The Van der Waals (VdW) surface, is probably the most commonly understood representation and which simply shows atoms as spheres whose radius corresponds to the atomic radius.
A popular representation among structural biologists is the secondary structure or ribbon diagram, it is used to reveal properties of the protein backbones such as sheets or helices.
Finally, the molecular surface representation is used to show a continuous surface that closely surround atoms of a protein and that also close small holes between atoms that are not accessible by small solvent molecules.
This method was first introduced to reveal information that is not salient enough with other types of representation, such as the presence of pockets and cavities buried in the protein structure and that can potentially host important reaction sites.
In scientific illustrations the shape of a protein is an important aspect to convey as it is tightly related to its function, and therefore the surfaces or VdW representations are often preferred and are also easier to understand.
Furthermore, VdW spheres and molecular surfaces can easily be stored as polygon meshes which are supported by 3D animation packages.
BioBlender[], Molecular Maya[], ePMV[], are examples of plugins for animation packages that were specifically developed to ease the loading and rendering of molecular surface meshes.

X-ray crystallography is limited in a sense that it is not capable of capturing large and complex structures such as organelles, viruses, or cells in their entirety.
Electron microscopy imaging, on the other hand, still does not offer enough resolution to capture individual atoms which make the segmentation task between proteins extremely challenging.
So far, only little is known about spatial arrangement of proteins that form greater structures and their modeling would be a cumbersome and manual task.
To fill the mesoscale gap between atoms and cells, scientists from the Scripps Institute in San Diego have developed cellPACK[], a tool to procedurally construct large mesoscale structures, such as viruses, or entire cells at atomic resolution.
cellPACK incorporates the most recent knowledge obtained from biology to generate these models such as proteins structures obtained from crystallography, concentrations and spatial distribution observed \textit{in vitro}, and 3D shape of compartments acquired from electronic microscopy.
They summarize all this data in structural descriptions which they call a recipe, and which is then used as input to generate entire models of viruses and cells via a packing method based on collisions constraints.
Their packing algorithm uses a spatial partitioning scheme to prevent structures from overlapping with each others.
As an output their tool generates a list which contains the position, rotation, and type of all the proteins that compose the organism.
Additionally their method also supports packing of fiber data such as DNA or RNA and is stored as control points in the resulting file.
The initial goal of cellPACK was to generate valid protein ensemble that forms an organism, that would also comprise atomic data in order to serve as input for large-scale molecular dynamics simulation.
Additionally, the generated structures can also be loaded in 3D rendering and animation packages for illustration purposes.
%, thus preventing illustrator to manually place and arrange proteins when depicting a larger protein ensemble.
These large models are highly valuable to us, as they comprise complex data that would have to be modeled manually otherwise, thus compromising the production of illustrative content.
They are also publicly available and can be easily updated with the most recent knowledge of cell biology.
However, the overwhelmingly large number of elements that compose these mesoscale structures begin to truly challenge animation packages that were not design with such constraints in mind.
While it is still possible to render still images in very high quality, real-time visualization of these models is simply not possible, even with simplified meshes. 
This affects the productivity of those who create the models, as well as those who are using it for illustration purposes and it also compromises the transition to the next generation of interactive scientific illustrations.

Although the polygon mesh is currently the most commonly used shape representation supported by animation packages and game creation software, it might not always provide the best performances for large and complex datasets.
Indeed to render highly detailed information meshes require an overwhelmingly large number of polygons which can stress the rendering pipeline and video memory usage.
To keep up with the increasing size of atomic datasets visualization experts developed new cutting edge techniques which do not rely on mesh data.
Tarini et al.[] introduced a novel visualization technique inspired from 2D billboards, a popular concept in computer games.
The technique consists of drawing camera-facing 2D sphere impostors rather than tessellated 3D spheres for rendering individual atoms.
As a result, to render a structure which comprise 1000 atoms only 4000 vertices would then be needed, which is rather low for the resulting image quality.
With their approach, they were able to interactively render large datasets (up to xxxk atoms) with very high quality details at a much lower cost than meshes.
Shortly afterwards, Lampe et al. [8] extended the billboard technique by leveraging the GPU rendering pipeline to reduce memory bandwidth usage and GPU driver overhead. 
Grottel at al. proposed to improve the rendering speed of large particle-based datasets by implementing occlusion culling to discard hidden particle chunks from the rendering pipeline, based on the depth information obtained in the previous frame.
Hence, only the sphere impostors that are garanteed to be visible will be processed by the graphics pipeline, thus increasing rendering performances greatly for very dense datasets.
Lindow et al. [11], subsequently presented a novel approach which is rely on ray-casting instead.
For each protein structure they store the individual atoms in small and fitting 3D grids and upload the protein grid on the video memory.
Upon the rendering they first draw the bounding box of the grid, and subsequently, in the per-fragment operation they cast ray for each single fragment in order to find the first hit with the atoms.
Their method supports rendering of very large structures with up to xxx atoms.
Mesoscale landscapes usually feature a high number of individual proteins that share the same structure.
In order to spare video memory usage which is usually restricted in size, they also use the principle of instancing, popular in computer games.
Instead of storing every single atoms on the video memory, they only upload the position and rotation of individual proteins to the video memory and upload each unique protein structure only once.
Falk et al. [3] further refined the method by introducing depth culling similarly to Grottel et al.[] and used level-of-detail for the grid structures to reduce computing for proteins that are located far away from the camera.
They reported being able to render large datasets representing cytoskeleton of a cell, with up to xx atoms at xx fps.
While the presented methods only support the VdW representation, a few techniques were also developed to improve the rendering of large and highly detailed molecular surfaces using GPU ray-casting and efficient supporting structures instead of meshes[][][]. 
However, none of these surface-based methods is yet able to compete in terms of performance with the most recent VdW methods which we previously presented .

\subsection{Visualization of Biological Systems}

Systems biology is the branch of biology concerned with computational or mathematical modeling of complex biological systems.
The organization of biological systems spans several scales; on the level of single cells they typically describe signalling or regulatory functions of living cells, such as energy production, gene expression, and ability to divide or die.
Such systems consists of reaction network between molecular agents such as enzymes, metabolites, or proteins, also known as pathway.
Based on the pathway description, scientists reproduce the dynamics of a system \textit{in silico}, via simulation tools, and observe the changes in species concentration over time.
The results of the simulation are then further analysed to predict and understand how these systems change over time and under varying conditions, and potentially develop solutions to health issues.
The complex reaction networks are usually described with a custom markup language, such as SBML[], and used as input for the simulation tools.
Similarly to protein structures the system descriptions are often shared with peers via public online databases[].
Biologists have developed several methods to simulate the dynamics of a system.
Depending on their modus operandi the modeling approach can either be deterministic or stochastic.
Models may also feature spatial information or be purely quantitative. 

Quantitative modeling (or Kinetic modeling) relies on the use of differential equation systems to compute the species concentrations at a given time and is therefore deterministic.
Results only vary according to the initial conditions such as concentrations and reaction rates that are predefined in the model.
Additionally, the models may also feature spatial information such as compartmentalization of species.
Quantitative was the first modeling method introduce and still remains very popular among system biologists because it is reliable and computationally inexpensive.
%A typical visual output for this type of simulation is a time-concentration plot.
Another type of modeling is agent-based modeling.
This method completely differs from the strictly mathematical approach used in Kinetic modeling.
It aims at reproducing the original reaction-diffusion behaviour of biochemical agents in three dimensional space and is therefore stochastic.
This technology was primarily developed to simulate and understand complex migration pattern among animal or human populations.
The concept was then transposed to study the behaviour of chemical species as more capable computer hardware became available and affordable.
With agent-based modeling, actors of systems are virtually represented as a 3D point in space and subject to constant random motion based on diffusion speeds observed in vitro.
New elements are introduced or removed according to individual reaction events.
Reaction events are triggered based on local proximity of potential reaction partners and reaction probability based on the reaction rates observed in-vitro.

It exists a few popular tools that aim at connecting the modeling, simulation, and data analysis in a single framework to facilitate the task of biologists, such as CellDesigner[] TinkerCell[] or VCell[].
These tools usually cover non-spatial models (quantitative modelling), except VCell[] which also supports the use of external agent-based simulation modules such as Smoldyn[].
At this stage, scientists studying these models have very limited ways to see how these mathematical models of physiology behave.
They can interact with the model by specifying input parameters to the simulation and the resulting visualizations are often time-concentration plots.
Even when the simulation method produce potentially interesting 3D trajectory data, these tools will favour highly abstracted visualizations which only experts can understand.
Such a visual form is hard to relate to what is visually observed in wet-lab experiments. 
In interdisciplinary physiological sciences this might hamper communication of results. 
However, the underlying data present in the models contains thorough dynamic descriptions of how these biological systems work.
These models informs us about the species present in a system, their quantities, location, diffusion speed, reaction partners, and reaction rates.
When associated with corresponding structural information this data could potentially to digitally reproduce and illustrative and dynamic model of a cell.
Biology, medicine, and other sciences can strongly profit from a visualization of physiology in order to gain, verify, and communicate the knowledge and the hypotheses in this field.
%Additionally, dynamics simulations, when computed along with the visualization could enable online changes of simulation parameters, such as species quantities or temperature, and directly observe how it would affect the system.
While the visualization of spatial trajectory data is often not relevant for the study of metabolic pathways, in specific cases, such as signalling pathways for example, such visualization might be informative to scientists that are interested in observing the spatial distribution of small signalling molecules overtime.
Few specific tools feature three dimensional visualization of particle trajectories obtained from agent-based simulation results.
CellBlender[] is a software conceived as a plug-in for the 3D animation package Blender, and which allow model design and visualization of particle-based models computed with MCell[].
%Via the user interface, it is possible to manually setup the model parameters, which are then fed to the external simulation module.
The cell compartments of a given model are represented as 3D meshes and can be modeled or loaded via the Blender interface.
Via the custom interface of the tool, expert users can specify the models parameters such as the species types, initial quantities, and diffusion speed.
MCell also supports 3D and 2D diffusion models for the particles.
3D diffusion is applied to elements diffusing freely inside a volume, while 2D diffusion is applied to elements that are embedded in a membrane and only diffuse along the compartment surface, such as channel proteins.
Users must then input the reactions of the model by specifying the participants, the products and the reaction probability.
Particles diffusing in 3D are also able to diffuse outside their initial compartment, and these crossing events must also be defined.
The user interface also features a multitude of advanced parameters to fine tune the modeling.
Finally, the user must specifies the duration of single step in nanosecond, and the desired number of steps. 
The duration of one simulation step will determine the precision of the simulation.
MCell then runs the computation offline based on the models properties setup in CellBlender, and produces large files that contain trajectory data for each single particle and for the given number of simulation steps.
%An additional file is also produced and contains the list of all reaction events, including the ID of participating elements, the reaction location and the corresponding time step.
The trajectory data is then converted to a key-frame particle animation format which is readable in Blender.
The simulation may then be played back for real-time exploration or rendered in movies.
Additionally, it is also possible to use custom meshes to visually encode the species type.
%The simulation approach, however, does not take into account the shape of the molecular structures, which are represented a simple 3D points, and thus the visualization of particle data using custom protein meshes will result in unwanted overlapping artefacts.
%To a certain extent, this information could also have an informative value for the laymen because it depicts complex processes in the form of a 3D animations.
%The viewing of actual three dimensional molecular interactions, such as the ones observed in scientific animations, could then be used as a mean to automatically generate expressive illustration of the simulated system.
Such trajectory data could potentially be used as such, to digitally reproduce the functioning of entire cells.
The resulting visualization would thus have an important informative value as it depict complex biological systems in the form of 3D diffusion and reaction animations embedded in their molecular environment.
A naive visualization of the raw trajectory data, however, may often results in an overly cluttered view due to the large number of elements randomly moving in every directions.
Although the display of trajectory data is valuable to expert users, it is almost incomprehensible for non-experts viewers.
Therefore, it is crucial to provide guidance to ensure that the underlying information, i.e., which elements react with each others and in which order, is perceived by the viewer.
Falk et al.[] proposed to enhance the playback particle trajectories with additional overlaid information to trace the history of individual particles, such as trajectory and previously undergone reactions.


%\subsection{Limitations of Related Work}
%
%So what, our vision is still not done.
%
%No real-time performace, only proteins
%No occlusion management
%
%Time scale discrepencies
%No real-time preformance, plus lack of camera guidance.
%
%****************
%
%
%Up to this point, the rendering methods presented in the literature have reached unprecedented levels of performance, in terms of size of supported dataset and rendering speed, thus enabling real-time rendering of large mesoscale models created with cellPACK[].
%However, the minimum requirement for a comfortable user experience is between 20 and 60 Hz on average for games, and higher than 60 Hz for VR content, which is still out of reach for very large datasets as the state-of-the-art method is capable of rendering 10 billions atom at 4 fps, which additionally leaves little to no room for other type of computation such as animation or physics simulations.
%
%Moreover, the presented solutions were specifically designed for efficient rendering of proteins data only.
%None of the techniques mentioned above have proved to efficiently support other types of molecular structures that exhibit much more complex organization, such as lipid membranes, nucleic acids or fibers, which ought to be taken into account for a truer depiction of molecular landscapes.
%Indeed, the properties of these structures can represent a challenge, especially for dynamic data because the assembling blocks of these structures are considerably smaller and also more numerous than with protein data.
%Several work focus on the modelling and visualization of such structures, such as life explorer[] or lipid wrapper[].
%However, none of these tools feature a visualization method that has the ambition to support overwhelmingly large datasets such as entire cells and which we deem crucial to achieve interactive and explanatory visualization of molecular biology.
%Furthermore, macro-molecular elements are usually densely arranged inside compartments (see figure), which may results in serious occlusion problems when interactively exploring a dataset.
%This visualization challenge has not yet been explored in the context of molecular visualization although it is crucial to address it to improve the quality of the user experience.
%It is also important to mention that none of the presented method above has been integrated into an animation or game creation package, which makes impossible for content creators to use it is a practical scenario.
%This review of the literature clearly underlines the lack of an efficient and integrated solution that would:
%a) Allow real-time rendering of datasets up to the size of a single cell
%b) Support all type of molecular structures efficiently
%c) Implement efficient occlusion management
%d) Provide tools that are embedded with animation or game creation package for optimized collaboration with various actors of the illustration process.
%
%Although previous works attempted to improve the raw visualization of particle-based visualization, there is still left to address the several grand challenges such as occlusion management for dense scenes or the issues that are due to time-scale discrepancies between entire processes and individual reactions, and which is described as follows: 
%On the one hand, observing the particle-based simulation at a slow pace to be able to keep track of individual elements and see interactions would require hours to explore the entire process.
%On the other hand, observing the simulation in fast-forward would shorten the viewing length but it would become impossible to observe important reaction events because of the fast pace at which elements would be moving.
%
%While solving ordinary differential equation systems of kinetic models is very straightforward, agent-based models must represent and simulate every single reacting entities, and that are usually present in large quantities.
%The simulation of particle-based systems is thus very demanding in terms of computation and is usually precomputed prior the visualization.
%This limitation thus prohibits online interaction with the simulation parameters and real-time exploration of multiple simulation scenario.
%Even most-optimized simulation tools that leverage the power of GPU computing [][], specifically developed for \textit{in-situ} visualization are still not able to deliver a true real-time user experience.
%Quantitative modeling methods do not feature 3D dimensional data but are also much faster to compute, and could easily be simulated along with a complex 3D visualization.
%Therefore it would also be interesting to explore the use of real-time quantitative information to animated 3D particle based on real simulation data but at a much lower cost than agent-based methods.


% far it has not been proven how this method would perform with other types of molecular ensembles present in living cells such as DNA fibers or lipid membranes.
%This method also requires additional supporting grid structures containing atomic data for the ray-casting rather than just the ray data.

%Our approach follow-up the work of Lindow et al. who rely in the GPU pipeline.
%We also inspired from Grottel et al. for the occlusion culling.
%We aslo inspired from the continuous level-of-detail approach from Parulek et al.
%We wished to stay away from ray-casting supporting structures for various reasons:
%
%Harder to setup, than simply using the raw data.
%Limitation of ray-casting, for complicated for optimization.
%Potentially larger video memory occupancy than raw data.
%No efficient support of fibers and lipid membrane structures.
%
%The method based on sphere impostors do not have these limitations.
%But they are also much slower.
%How to improve them ?

\section{Rendering and Composition of Molecular Landscapes}

Up to this point, the rendering methods presented in the visualization literature have reached unprecedented levels of performance, in terms of size of supported dataset and rendering speed, thus enabling real-time rendering of large molecular structures such as those created with cellPACK[].
The most recent presented solution is capable of rendering 25 billion atom at 3.6 fps in HD resolution.
However, the rendering approach still fails to provide a comfortable user experience.
One expects between 24 and 60 Hz on average for interactive entertainment, and at least 60 Hz for dome and VR content.
The computation should also free enough resources for remaining computation, as for instance the physics simulation of the molecular bodies.
None of the techniques mentioned above have proved to efficiently support other types of molecular structures that exhibit much more complex organization, such as lipid membranes, nucleic acids or fibers, which ought to be taken into account for a truer depiction of molecular landscapes.
Indeed, these structures are much more challenging to render, because the assembling blocks of these structures are considerably smaller and also more numerous than with protein data.
In order to provide a true real-time experience we decided to investigate new rendering approaches that would address all these limitations.
We finally opted for a impostor-based method for the design of our rendering pipeline, which follows-up directly the work of De Lampe et al.[].
An advantage of sphere impostors is that they do not require additional supporting structures for the rendering[] and are also much simpler to render than surfaces while providing high quality surface details.
The optimizations which we developed to increase the performances are inspired from well known computer graphics technique often used in games such as level-of-detail, instancing and occlusion culling.

\textbf{Level-of-detail}

Level-of-detail (LOD) is a method often used in computer games to cope with the limited polygon budget of real-time applications.
The principle consists of drawing simpler mesh representations for distant objects that have less pixel coverage to reveal high-frequency details. 
From an original 3D model with a high number of polygons, proxy models are generated to create an atlas of models featuring gradually less polygons and high-frequency details.
Upon rendering of a model, the LOD proxy is then selected based on the distance to the camera.
The further away an object lies, the less details can actually be observe with human eyes and the less polygons should be then processed.
This concept was applied to molecular visualization by Parulek et al.[] who presented a continuous level-of-detail for molecular surface rendering.
Molecular surfaces such as SES[] are often use for scientific exploration of cavities and pockets.
Because computing molecular surfaces in real-time for dynamics data is expensive, they propose to simplify the molecular structure in the most further background region.
They seamlessly transition from highly detailed surface rendering in the region of interest for scientific exploration, to Gaussian surfaces in the context region.
Gaussian surfaces are more trivial to compute but also provides less high frequency details needed.
To push the rendering capabilities even further they also simplify the atomic structure of the proteins for the most distant context region.
They use clustering algorithms to simplify the atomic structure of a protein with fewer and larger spheres, as seen in figure X.
Since the structure comprise less spheres to contribute to the surface the computation of the distance field is much less expensive, but still preserves low-frequency shape details.
We use a similar approach to compute LOD proxies for each protein type. 
Instead of computing and rendering Gaussian surfaces we simply render the larger spheres, or meta-atoms, resulting from the clustering obtained as 2D impostors.
Clustering allows a reduction of the atomic dataset from 75pc for the first LOD proxy up to 99pc for the most simplified proxies.
We also use different shading materials for original atomic structures and the proxies.
For proteins closer to the camera and showing the entire atomic data we highlight the atom details with high-frequency illumination.
For proteins located further away that are showing only simplified structures we only highlight low frequency details to make the meta-atoms less salient similarly so smooth Gaussian surfaces representations.
Although simplified protein structures are much faster to render and original structures, when dealing with a large number of protein it is also important to limit the number to draw command to limit GPU-driver overhead.
Therefore we also propose and optimized rendering pipeline that allows to switch between proxies levels on the fly and render the scene in a single draw command, thus approching zero-driver overhead.

\textbf{Instancing}

Instanced drawing is a concept widely used in computer graphics that aims at reducing the memory bandwidth and usage as well as reducing the GPU-driver latency cause by a large number of draw commands.
This concept was applied by De Lampe et al.[] who used the geometry shader stage to instantiate entire atomics structure of amino acids, or residues, directly from the rendering pipeline.
Amino-acids are the building blocks or the proteins, and there is around 20 different types of animo-acid.
They initially store the atomic structures of each animo-acid types in the video memory, as well as the position, rotation and type of each amino acids that compose a single protein.
With their method they are able to render entire amino-acid for a single initial per-vertex operation.
During the vertex shader execution, amino-acid properties such as position, rotation and type are read from the main memory and passed on to the geometry shader.
The geometry shader program then fetch amino-acid structural properties such as local atom positions and radii from the main memory, and the local positions are transformed with the reside position and rotation to determine the world atom position.
Based on the world atom positions and new triangles are injected around the centroid to form the camera facing 2D sphere impostors similarly to Tarini et al.[]
It is also possible to launch the execution of multiple verter shader programs in a single CPU operation, thus reducing the latency accumulation caused when sending rendering command to the GPU multiple times.
Given a protein composed of a 4000 atoms and 250 amino acids the memory footprint of a protein would thus be reduced from 16000 numbers (4000 x 3D positions and atom type) to 2000 numbers (250 * 3D positions + atom type + 3D rotations).
Although there is finite number of animo-acid structures, it also exists a infinite number of possible rotational conformations, which means that it is challenging to accurately depict protein structures with this approach.
In order to render very large scenes efficiently it would be ideal to apply the same concept to entire proteins instead of residues to address this limitation
Additionally, this would considerably reduce the memory footprint of the scene as only the type, position, and rotation would suffice to describe a protein.
Finally, the geometry also introduce an considerable latency in this particular use case, for it was only designed to inject small number geometry efficiently.

The tessellation stage is a feature that is now present on most recent graphics hardware, and is also available on mobile devices.
Similarly to the geometry shader this shader stage is designed to dynamically inject primitives in the rendering pipeline, but it supports injection of up to several thousands of vertices in a much more efficiently manner.
While the geometry shader is only design to inject a few dozens of vertices maximum, the tessellation shader is able to efficiently inject thousands of vertices by dispatching the work on multiple threads.
Initially the feature was developed to selectively increase the level-of-detail of meshes based on the camera distance based on the curvature of a surface.
The tessellation is also able to inject other types of primitives than polygons, such as lines or vertices.
We use this feature to dynamically control the number of atoms or meta-atoms that shall be drawn, directly in the rendering pipeline.
Similarly to De Lampe et al.[], only one vertex shader thread is required to draw a single protein.
The previous stages of the pipeline are fetch important protein information such as position, rotation and type and these details will be passed on to the next stages of the pipeline.
Based on the protein type and the distance to the camera which defined the level-of-detail, it is then possible to notify the tessellation engine how many sphere should be drawn for the given protein.
The tessellation engine will then dispatch threads executions, one for each sphere to be drawn at this stage the primitive type of a spheres is treated as a single point.
The $local_ID$ of each thread is used to fetch the corresponding sphere information from the main video memory, such as the local position and radius of the atom or meta-atom.
After transforming the local sphere position with the protein position and rotation the sphere centroid is passed on to the geometry shader.
Subsequently the geometry shader is used to inject the remaining vertices around the sphere centroids to form the 2D camera facing sphere billboard.
A nice perk of this technique is that it does not rely on supporting structures and thus work equally well with numerous large protein structures and numerous small molecular structures such as lipid membranes.

\textbf{Occlusion Culling}

When rendering large scenes, a large number of geometries are processed through the rendering pipeline which may be too overwhelming for the graphics hardware.
The per fragment processing is the rendering stage which the most demanding and causes a bottleneck in the pipeline.
Mesoscale datasets such as the one generated with cellPACK often result in a very dense arrangement of macro-molecules.
Because the scenes are very dense, a large number of spheres might overlap each other at a single pixel location.
which is turns results in a overly large number of depths tests and may slow down the rendering.
An efficient way to reduce this computational load is occlusion culling.
Occlusion culling is a popular method is computer graphics that ensures that instances that are not visible in the final render at not processed at all.
It exists on modern graphics hardware a fixed functionality called hardware occlusion queries (HOQ) and which allows the user to determine the number of visible pixels of rasterized geometry based on an input depth texture.
In some scenario the depth texture may be generated via a depth-only pre-pass or simply recylcled from the results of the previous final rendering.
Grottel et al.[] presented an efficient rendering pipeline for large particles-based dataset, using HOQ to discard large chucks of the dataset hidden in the current viewport.
They use an uniform grid to spatially partition the data, and perform occlusion queries for each grid cells using cells's cubes as bounding geometries.
Each query result is individually read back to the application after a certain latency which is due to the processing in the graphics pipeline.
Additionally the queries are all performed in serial resulting in a latency accumulation for each individual draw calls and caused by the GPU driver overhead.
For the specific use case of Grottel et al.[] this approach is reasonable because of the relatively low resolution of grid cells they used (15x15x15).
For our specific use cause, we would like to perform occlusion queries for each individual macromolecule.
Averagely complex scenes generated with cellPACK may easily comprise up to millions of individual instances when small lipid molecules are counted and therefore HOQ is guaranteed to perform poorly with those scenes.

A more suitable approach would have to be specifically designed to reduce execution times of individual queries and also to limit GPU-driver overhead.
Most commonly used occlusion culling techniques are image space because they are not depending on the complexity of the geometries.
Hierarchical Z Buffer is a method introduced by Green et al[] and is widely used to quickly compute visibility look-up based on a single input depth-map.
Based on the input depth map they compute a series of mip-maps with a custom downsampling method to only retain the deepest values during the downsampling.
The textures are then used to perform occlusion look-up and thus determine the visibility of an object.
To perform occlusion queries they use a bounding volume in the form of a camera-facing square.
Then, based on the size and position of the square they perform a series of look-up in the HiZ buffer at a specificity chosen resolution to minimize the number of texture reads.
In case the depth of the square is deeper than all the values queried in the HiZ buffer the object in then guaranteed to be hidden and may safely be discarded from the rendering pipeline.
Due very small number of texture look-up when sampling low-resolution mip levels this technique is very fast to execute individually.
However, without a proper batching mechanism the overhead cause by the GPU-driver will simply be too high to allow decent rendering performance.
Once way to perform the queries in a single CPU execution command is to use GPU computing such as CUDA or compute shader programs.
Additionally to the low GPU-driver overhead the computation of the queries will also be executed in parallel thus speeding-up the operation.
 
\textbf{Fibres Structures}

An utterly important component of living organisms are fibre structures such as DNA, RNA or (...).
Similarly to protein data, a challenge when rendering dynamic fibre structures is memory usage and bandwidth.
Fibres such as DNA, are composed of small molecules called nucleic acids, also known as bases, and which are made out of a few dozen atoms.
One approach to render fibre structures could be to store the position, rotation and type of each nucleic acids and to render the bases with the same pipeline used for protein data and described above.
However, we foresee two issue with that approach.
Firstly, the memory footprint of DNA strands might simply be too large to store the genome data of entire cells the video memory.
Indeed, the entire genome of E.Coli for instance is composed of xxx individual base pairs, which represents xxx Gb of data.
Secondly, simulation tools that are able to reproduce the dynamics of DNA fiber structures are all using CPU-based algorithms.
Assuming that storing large static structures is already a challenging enterprise, the rendering of animated structures would very likely have to be streamed to the GPU instead.
Interactive rendering of animated DNA structures would therefore be limited with this approach because the cost of memory transfer between CPU and GPU would slow down the rendering considerably.

Our solution to limit the memory footprint of fibre structures is too only update the control points of the curve instead.
(This solution can save up to XXpc of memory space)
Additionally since only the curve data is needed to render these structures, the simulation of the dynamics aslo becomes much more trival.
Indeed the simulation of simple dynamic strands is much less computationally demanding than more complex DNA strands.
Moreover, mainstream physics animation tools that are GPU-based may be used instead of CPU-based standalone simulation tools, which guarantees a considerable performance boost for the real-time simulation and simulation use case.
The fibre rendering pipeline which we developed similarly to the protein data, uses the tessellation shader to dynamically inject the spheres that compose each individual nucleic acids.
In order to support different types of fibers it is important to first understand their building rules.
In the case of DNA, a well known structure is the B-DNA that exhibits the recognizable double-helix pattern.
The structure is also a very simple to model: a spacing of 3.4Å and a rotation of 34.3 degrees between each base. 
Based on these rules we are able to procedurally generate B-DNA strands based on path control points via GPU dynamic tessellation.
It is important to mention that the proposed modelling approach does not aspire to provide a strictly accurate depiction of DNA structure.
Instead we generate an resembling representation of the structure which is fast to compute and designed for illustration purposes only.
The pipeline is designed to render an entire curve segment form only one initial per-vertex program.
As an input, the vertex program receives the controls points information for the current segment as well as the building rule of the fibre structure.
The building rules and the segment curvature are then processes, and each single base of the segment is given a world position and rotation.
The tessellation engine is then informed about the number of primitives to inject in the pipeline, and the base information is passed on to the next stages of the shader.
When processing individual spheres in the tessellation stage, the corresponding local atom position is then fetched from the memory and then transformed with the world position and rotation of the pair it belongs to.
Finally, the sphere centroid position and radius is passed on to the next stages of the shader to create the 2D sphere impostors.
Additionally, previous optimization initially developed for protein data such as occlusion culling and level-of-detail can also be seemlessly employ with the fiber use case.

\textbf{Occlusion Management}

The phenomenon of molecular crowding is used to describe as solution when high concentrations of macromolecules such as proteins are present.
Such conditions occur routinely in living cells; for instance, the cytosol of Escherichia coli contains about 300–400 mg/mL of macromolecules.
Therefore an accurate depiction of living organisms often result in a very dense arrangement of macromolecules as shown in Figure X[].
Without efficient means to selectively remove occluding objects, it would therefore be impossible to observe hidden internal structures that play essential roles in the functioning of biological systems.
In scientific illustrations and visualization, cutaway views are often employed as an effective technique for occlusion management in densely packed scenes.
However, a limitation of strict cutaway views is that important contextual information is removed.
Illustrators must make sure that the essential information, e.g., the ratio of multiple molecular ingredients is represented, and not simply clipped away.
While mainstream visualization and illustration software feature cutaway tools, they do not provide the means to performed advance scene composition for such scenes.
Transparency is another approach to solve occlusion problems, although the computational cost of full-fledge transparency will be too significant for large molecular scenes featuring several hundreds of overlapping elements.
Furthermore, due to the presence of a large number of potential occluders the use of transparency will result in overly complex images which would affect the quality of the visualization.

We propose a novel method for solving occlusion problems due to molecular crowding.
In contrast with existing techniques, we take advantage of the characteristics of complex molecular landscapes such as the scenes modeled with cellPACK.
These models usually comprise hundreds of thousands of individual macromolecules, however many of them share the same structure.
Therefore, by reducing the concentration of elements sharing a similar structure, we may reveal hidden structures and also preserve important information such as the structure of contextual elements and their location.
This concept resembles the “Screen-Door Transparency” technique popular in the early days of computer graphics and where transparency is achieved by placing small holes in a polygon to reveal what is present behind.
When reducing the concentration we also ensure that elements are removed uniformly across the scene to preserve the input proportions of the spatial distribution.
A potential limitation of this approach is that it will communicate erroneous information about the concentration to the viewer.
In order to avoid misconceptions, we optionally propose to display the removed elements with a ghosting effect such as transparency or contours only.
The main difference between the ghosting effect and full fledge transparency is that only the last occluding elements are blended on top the opaque and visible elements to minimise visual clutter.

To assist the scene composition, we additionally display a bar chart over the view that provide real-time quantitative feedback about the visibility of each macromolecular type.
A single bar comprise three distinct regions that indicates the visibility properties for a given species as show in Figure[].
The grey region bar indicates the number of macromolecules that are currently discarded from the rendering.
The dark green region indicates the proportion of rendered molecules that are currently visible, while the light green region indicates the proportion of them that are currently occluded by other macromolecules.
The bar chart provides an overview of the visibility properties which then serve as guidance for composing the scene.
For instance, if the user wishes to observe a particular species he will immediately be informed about the number of macro-molecules occluded by other structures, and will adapt the visualization accordingly.
The modulation of the number of visible elements is also done via the quantitative view by simply dragging the border between the grey and green regions. 
Another useful functionality for scene composition is the selection of macro-molecular types as objects of interests (OI) which guarantees occluding macro-molecules of a different type to be discarded.
Since this method is view dependent it is necessary to compute occluding elements routinely when the camera position is updated.
Therefore we developed a custom clipping pipeline using GPU computing to guaranty a smooth user experience even with scenes featuring a large number of macro-molecules.
Macro-molecules that are set as OI are first rendered in a separate off-line depth texture and used as input to perform image-based occlusion queries for each of the remaining elements and detect occluders.
Additionally to our quantitative approach for occlusion management we also provide support traditional clipping objects such as planes, cube or sphere that can are manually placed in the 3D scene.

\section{Emulating the Machinery of Life}

Biologists have recently started the ambitious enterprise to model the atomic structure of entire viruses or cells.

These models are very interesting for scientific and educational exploration because they comprise structural information of multiple scales.

These models can represent a challenge for real-time rendering but optimization inspired from computer games may we developed and adapted to speed up the rendering and advanced composition of commodity hardware.

However, these models only represent statically microscopic organism and do not feature any information about the future states.

The HIV virus for instance, undergoes multiple transformation during his life cycle, and showcasing only one single state would fail at revealing the functioning of the virus.

Scientists at the Scripps Institute of San Diego have already produced two different states of the HIV virus, mature and immature [show images].

However, this modeling approach is not yet designed for the creation of animated datasets.

Although it is possible to create a multitude of models to transition of from state to another there is no correspondence between two models that would allow to generate transition between two snapshots.

Additionally to produce a large number of models would be a challenging enterprise because the modeling setup is not streamlined, and each snapshot would require cumbersom manuall steups.


The models were initialy developed to serve as input for dynamic simulations tools such as molecular dynamics or brownian dynamics that require an initial structure which is valid, i.e., a logical arrangement of proteins without overlapping structures.

Limitation of brownian dynamics, local phsical atomic interaction, complex to compute large systems and small time steps must be used.


Computational biology also comprise simulation tools that are able to simulate an coarse approximation of molecular trajectories as well model individual reactions for an entire biologocal system.

Allows to model larger and longer simulation, because it greatly simplifies molecular interaction compared to BD, MD.

In particle-based modeling each molecular agent is represented as a 3D no matter its size.

[Show diagram]

results are very cluttered.

Although previous works attempted to improve the raw visualization of particle-based visualization, there is still left to address the several major grand challenges.

Visual guidance, temporal close-ups, bladibla.
Interactivity.

\subsection{Observing Multiple Time Scales at Once}

Particle-based modeling, also known as agent-based modeling, reproduces entire biological systems to explore their dynamic properties.
Particles are individually modeled and interactions between them are virtually taking place in the 3D space.
Additionally to quantitative information which is valuable for understanding the functioning of a system, the modeling approach is also capable of producing 3D trajectory data and reaction log as output which can be used to visualization of spatial data.
Falk et al.[] designed visualisation tools to playback the particle trajectories resulting from the simulation in 3D space.
A major challenge with this type of visualization is visual clutter due to the large number of particles diffusing in every direction.
In order to visualize individual reactions is it therefore necessary to close-up on participating particles and also to reduce the playback speed in order to keep track of individual reactions.
Because particle simulations operate at very small time steps, typically of the order of nanoseconds, the resulting number of steps can often be very large. 
At the reduce pace required to see individual reactions, the viewing of the entire simulation frames to lead to overly long visualization sequences.
To shorten the duration of the visualization, it is common to only display simulation frames spaced at a constant given interval. 
This is usually referred to as fast-forward or timelapse.
The time-scale discrepancy between process and reaction thus complicate the visualization task as the viewer must manually switch from fast forward to normal speed in order to observe the multiple scales of a phenomenon.
To overcome this limitation and improve the user experience when observing particle-based simulations of biochemical reactions simulation we propose a new type of visualization that enables the viewing of individual reactions while playing back the simulation in fast forward.
We believe that effective visualization can be achieved by respecting a few guidelines which we enumerate as follows:

.The visualization should show the simulated process in a reasonable amount of time, irrespective of the number of simulation frames.

.Individual particles should move slow enough be traceable with human eyes, especially those with a high degree of interest.

.Events of interested, such as reactions should be salient and last enough time in order to be seen by a human eye.

.Despite eventual alterations to respect previous guidelines the visualization should be as realistic as possible to avoid misconceptions. This requirement is in accordance with the results of a study by Jenkinson et al. [14], which demonstrated that a more realistic depiction of a process can enhance the viewer’s understanding compared to a highly abstracted one.

\textbf{Speed Reduction}

In order to satisfy R1 we only show simulation frames spaced at a constant given interval, for instance show one frame every thousands frames, while preserving a fast pace between two displayed snapshots.
Fast forward visualization results in more visual clutter as the position leap between two consecutive displayed frame is greater than when showing the entire trajectory at the same pace.
In some configurations the leap might be too large and the number of particle too high to keep track of a single particle between too consecutive frames.
To satisfy R2 we apply a speed reduction filter to shorten the trajectories of individual particles.
The filter consists of reducing displacements between the current position of particles and their current trajectory positions, according the speed reduction factor which is arbitrarily defined, as shown in Figure[x].
Particles thus follow their original trajectories while keeping their distances.
This produces a small delay between particles and their original trajectories but since the magnitude each displacement is proportional to the distance of a particle and its trajectory, this delay does not accumulate and remain constant over time.
As a result of the shorten trajectories, particles travel less distances and their motion is much smoother and easier to follow by human eyes.

\textbf{Reaction Highlighting}

In particle-based simulation of biochemical reactions networks, reactions are punctual events that occur upon collision of two potential reaction partners.
In the event of a reaction the resulting products will immediately be injected in the system as the operation is performed in single simulation step.
Therefore it might be difficult to observe single reactions.
Additionally, when viewing the simulation in fast-forward, many important reaction events might be simply omitted due to frame dropping.
Without showing reaction events, molecular agents will appear and disappear from the visualization without providing the necessary visual clues to understand what might have caused it.
We therefore prolong the duration of the reactions to make them stand out and to inform the viewer about the nature these events.
Shortly before each reaction event and until the end of the reaction as occurred we select the reaction participants and attracts them towards the reaction location.
During this animation the original trajectories or reaction participants is omitted.
To emphasize reaction events, reacting elements are highlighted with vivid colors, thus contrasting with the rest of the scene.
The slow attraction animation and the color highlighting thus grantees that the viewer is informed that a reaction is about to happen.
Once a reaction is accomplished, the products are introduced and are progressively subject to their respective original motion.

\textbf{Lens Effect}

Because of the slow movement of the particles compared to their original trajectories, the viewer may be misguided about the true diffusion properties of molecular agents.
To preserve a realistic impression of molecular motion despite trajectory reducing, we introduce a temporal focus+context technique that applies visual abstraction of molecular trajectories solely in the foreground (focus), while showing more realistic -yet often untraceable- motion in the background (context).
By showing the actual particle trajectories in the background we want to create an illusion of chaos, thus informing the viewer about real diffusion speed while allowing him to observe important reaction events in the same view.
We propose two methods to achieve this effect.
The first method operate in object space, we define a region anchored in front of the camera in which molecular agents will be subject to higher speed reduction.
Outside of this region we progressively decrease the speed reduction until reaching the background zone where the original particle trajectories are shown.
The second method we propose operate in image space.
We limit the displacement of particle to a distance in pixel space with is based on the smooth pursuit eye movement limit defined by psychology research.
When using a perspective projection in the visualization, this maximum velocity lens automatically leads to the effect that elements close to the camera appear to move much slower than those
further away in z direction. 
In fact, their screen space velocity is approximately the same, This illusion is due to the differences in pixel coverage of particles that are located in the background.
This effect results is very harmonious results as a continuous transition between front and background is easier to acheive compared to the world lens approach which require manual fine tuning steps.


\subsection{Quantity-Driven Particle Animations}

In systems biology, it exists various modeling approaches that are either deterministic, such as quantitative modeling, or stochastic, such as particle-based modeling.
One advantage of the agent-based approach for the visualization, is the presence of spatial information which can easily be displayed in a 3D view.
Although the output is usually very cluttered, it is possible to apply filtering methods to improve the visualization as shown in Section[].
However, the computation of particle-based models is much more demanding compared to quantitative modeling, because it must accounts for the reaction and diffusion of each single reacting entities, which are usually present in large quantities.
The simulation is therefore often precomputed prior the visualization.
As simulations are complex to setup and to compute, the creation and exploration or multiple scenario is thus slowed by this workflow.
Additionally, with large and complex model the resulting trajectory files may be very large, over xx GB for XX frame and XX individual particles, which is impractical to manipulate when dealing with a multitude of different scenario.

Our goal is to digitally reproduce the dynamics of the machinery of life, and therefore we are mostly interested in mapping spatial and quantitative information to structural information in three dimensional space. 
A more efficient workflow for this use case would be to visualize the particle positions on-the-fly as the simulation advances.
With such approach, it would be possible to influence the course of a simulation, for instance, increase the temperature, or introduce new species, and directly observes the impact of these changes without having to run another simulation or deal with overly large files.
Most-optimized simulation tools, such as Smoldyn[], are able to compute single simulation steps in a matter of seconds, thanks to parallel adaptation of the simulation algorithm computed on a single GPU.
A few tools also propose \textit{in-situ} visualization of particle-based models computed in real-time on the GPU.
However, the computation is still too demanding to deliver a smooth user experience even of high-end commodity hardware, which prohibits the use of online simulation for interactive and explanatory applications.

Additionally, to visualize and understand a biological system, one must be able to observe the logical cascade of reactions described in the reaction network, as depicted in scientific animations.
With particle-based modeling, it is impossible to influence where and when reactions will occur.
Therefore, the viewing of an entire cascade of reactions may be very tedious because it requires manual spatial exploration and waiting times between successive reactions.
To overcome this issue, we would have to gain control over where reactions might occur.
This can only be achieved by decoupling the quantitative information from the spatial information.
Quantitative modeling methods, such as kinetic modeling, do not feature particle trajectory data, and are much faster to compute and could easily be simulated along with a complex 3D visualization with high frequency refresh rates.
To address the previous limitations of particle-based modeling, we thus chose to explore the use of quantitative information to drive 3D particle animations in real-time.

With particle-based modeling, the behaviour of individual particles directly influences the concentration of species overtime.
Individual reactions are only triggered by collision events, for example, given a reaction A + B -> C, if a reactant A and B are closely located from each other, then a reaction is likely to occur.
Element A and B subsequently fuse to produce element C, which increases the concentration of element C and decreases the concentration of elements A and B.
We propose a new type of particle system where the behaviour of particles is purely driven by quantitative information.
In particle-based simulations, individual agents are actors of their own fates.
We introduce a new type of agent, whose behaviour mostly depends on external parameters, and which we dub passive agents.
The passive agents, do not play any role in the simulation process, their only function is to act as a visualization proxy to show quantitative information in three dimensions.
While the visual output is hardly distinguishable from an actual particle-based simulation, the benefits of this approach is two fold.
Firstly, the simulation of the reaction network is very lightweight to compute, which makes this approach much more usable for interactive applications.
Secondly, the spatial information is completely decoupled from the simulation, which means that we can have control over where reactions will occur.
This approach grants us the freedom to dynamically trigger a cascade of reactions directly in the viewport in order to facilitate storytelling of complex reaction networks.

The workflow of our passive-agents system is laid out as follows:
On the one hand, we have a biological system described as a reaction network and modeled with a scientific simulation software using a kinetic modeling approach.
On the other hand, we have a 3D scene filled with potential reactants, and which is setup according to the initial conditions of the model, such as the initial quantity and location of each species.
Each passive-agent additionally undergoes a 3D random walk type of motion to simulate the diffusion process, similarly to traditional particle-based simulation.
We then routinely query the quantitative simulation to fetch information about the number of reactions that are meant to occur at time t.
Assuming a reaction of type A + B -> C, for example, the particle system will first randomly select two elements A and B based on their their spatial proximity.
The two particles will then be subject to attraction forces until they enter in collision.
Upon collision of the reactants, the reaction is performed, products are injected and the reactant are removed from the system.
Finally, the reaction products return to a normal diffusion behaviour until they get chosen for a subsequent reaction defined in the model.
By default, the reaction participants are randomly chosen in the 3D scene, but it is also possible to set a higher priority to a few elements present in the viewport, in order to show cascades of reactions without having to browse through the entire scene.



%We will then exert and an attraction force to these two elements in order for 
%
%
%The two elements will them exert 
%
%For the duration of the reaction the tw
%
%
%
%
%
% at a given time t we extract from the quantitative simulation how many reactions of type  are meant to occur.
%
%
%
%To explain the concept of the passive agents in more details:
%let us first assume a given raection network which is computed with a quantitative simulation tool.
%And let us also assume a 3D scene filled with potential reactants, and which is setup according to the initial conditions of the model such as the quantities of each species, and the compartment.
%Each single agent is diffusing freely, similarly to traditional particle-based simulation.
%Then at a given time t we extract from the quantitative simulation how many reactions of type A + B -> C are meant to occur.
%Given this information elements A and B are randomly chosen based on their spatial proximity and the two reactants are forced to meat at a given point to produce and new element C.
% is tedious as it require manual spatial exploration, and .
%Instead of lurking for reaction events we may force them to occur directly in the viewport thus 
%
%
%
%
%
%
%
% purely act a 
%
%The particles simply play the role of a view for the quantitative simulation.
%
%
%%Therefore we dub this new type of agents passive agents.
%%with our approach the behaviour of individual in purely depending on external environmental factors.
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%While
%
%
%which purely acts as a spatial view for quantitative information.
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%it will be challenging to observed individual reactions as they si
%
%
%would be very hard to anticipate individual reaction with such simulation 
%
%
% with online simulation of particle-based reaction diffusion.
%
%Playback offersmheads hup
%
%
%simulation methods are still to computationally demanding for 
%
%
%far from being usable in interactive entertainments 
%
%
%reaching the minimum requirements in terms of framerates 
%
%Finally a limitation of in-situ vsuai
%
%
%
%
%
%
%
%latency of the simulation coupled with the visualization of
%
%
%
%
%that leverage the power of GPU computing [][], 
%
%
%specifically developed for \textit{in-situ} visualization are still not able to deliver a true real-time user experience.
%
%
%
%In some case t
%
%
%As simulation a complex to setup
%
%
%This prohibits online interaction with the simulation parameters and real-time exploration of multiple simulation scenario.
%
%
%
%Productivty ? Complexity to generate datasets ? Educational perspective ?
%
%
%
%Even most-optimized simulation tools that leverage the power of GPU computing [][], specifically developed for \textit{in-situ} visualization are still not able to deliver a true real-time user experience.
%
%Quantitative modeling methods do not feature 3D dimensional data but are also much faster to compute, and could easily be simulated along with a complex 3D visualization.
%
%Therefore it would also be interesting to explore the use of real-time quantitative information to animated 3D particle based on real simulation data but at a much lower cost than agent-based methods.
%
%
%
%
%
%particle trajectory data
%
%
%
%particle-based approaches have the advantage of featuring spatial information that can easily be shown in a 3D view.
%
%
%
%Particle-based simulations have 
%
%particle-based simulations of biochemical reactions
%
%No interaction
%No control on reaction location








%, participating reactants are attracted toward the reaction location. 
%
%Before each reaction event 
%
%Information about reaction locations, times and participants is first
%read out from the simulation data in order to anticipate reaction
%events during the visualization. We use this information to associate
%new or missing particles between consecutive frames to their
%corresponding reactions, thus the birth or death of particles will
%only occur as a result of a reaction event. 
%
%Then, a few seconds before each individual reaction and until the end of the reaction, participating reactants are attracted toward the reaction location. 
%
%It is worth mentioning that during this operation particles are not longer
%subject to their original trajectories. 
%
%In order to ensure all reactants to meet each other at the right time, we apply a per-frame displacement to the particles in direction of the reaction location. 
%
%We also adapt the magnitude of these displacements according to the distance between particles and reaction sites in order to obtain uniform
%reaction durations. 
%
%To emphasize reaction events, the color of reacting elements is highlighted, thus contrasting with the rest of thescene. 
%
%Once a reaction is accomplished, the elements are subject to
%their respective original trajectories again.
%
%, it is hard to understand the addition or the disparition of particles.
%
% because they do not last longer than a simulation step or might simply be skipped due to frame dropping.
% 
%while keeping a certain distance between them.
%
% are only approaching their original trajectories without ever reaching it.
%
%%Subsequently, when displaying the next trajectory snapshot, particles will then be displaced from their current position, resulting from the previous speed reduction, toward the next position sampled from the trajectory as shown in Figure[x].
%
%As a result, particles are only approaching their original trajectories without ever reaching it.
%
%This produces a small delay between a particle and its trajectory but since the magnitude of a single displacement is proportional to the distance of a particle and its trajectory, this delay does not accumulate and remain constant over time.
%
% and its current position and the destination point sa
%
%the next destination currently sampled from the trajectory data
%
%of a particle and its position currently sampled from the trajectory data.
%
%to the destination point and an arbitrary defined speed reduction factor.
%
%This will results in a small delay between a particle and its orginial trajectory.
%Therefore the delay
%
%The magnitude of the displacement is proportional to the distance to the destination point and an arbitrary defined speed reduction factor.
%
%Rather than leaping straight to the next position we perform a displacement in the direction of the actual sampled position but we reduce the magnitude proportionally to an arbitrary speed reduction factor.
%
%The resulting motion is thus smoother as particles browse smaller distances while remaining in the vicinity of their original trajectories.
%
% a delay between the current position of a particle and the next position sampled from the dataset.
%
%Rather than leaping straight to the next position we perform a displacement in the direction of the actual sampled position but we reduce the magnitude proportionally to an arbitrary speed reduction factor.
%
%Consequently, individual particle browse less distance,  while remaining in the vicinity of their original trajectories.
%
%And since their speed is reduced it also possible to keep track 
%
% it might even be impossible 
%
%By reducing the number of 
%
%Reducing the number of displayed frame thus reduce the overall viewing duration for the entire simulation.
%
%Consequently, as many trajectory step are omited,  individual 
%
%%Initially we must produce a simulation data with a very high temporal resolution in order to 
%
%Observing an entire biochemical process can therefore lead to overly long visualization sequences
%
%However, due to the time scale discrepancies between individual reaction and simulated systems, the viewing of the entire simulation at the
%
%
%is able to produce trajectory data as well as reaction history.
%
%represents individual actors of 
%
%For experts not people.
%
%there is still left to address 
%
%cluttered too much thing going one plus problem with mutiple temporal scales.
%
% such as occlusion management for dense scenes or the issues that are due to time-scale discrepancies between entire processes and individual reactions, and which is described as follows:
%
%On the one hand, observing the particle-based simulation at a slow pace to be able to keep track of individual elements and see interactions would require hours to explore the entire process.
%On the other hand, observing the simulation in fast-forward would shorten the viewing length but it would become impossible to observe important reaction events because of the fast pace at which elements would be moving.
%
%Time steps are much larger, which allow 
%
%an entire reaction 
%
%model the entire reaction network of a reaction network and also 
%
%While this modeling approach is not designed to incorporate dynamic information, it was de
%
%These models are a static representation and only constitute a single snap-shot in the multitude of possible states.
%
% modeling entire animated structures would however be  very challenging with this approach
%
%The task of baking and animated sequence would 
%
%the means to model the structures of very large 
%
%Multiscale molecular datasets available form the 
%
%The machinery





\section{Section 4}

So what, our vision is still not done.

We have large structures but cannot render then quickly enough.
Crucial to be quick.



%so that a single initial per-vertex program 
%is designed to render an entire curve segment.
%The proposed modeling approach aims at provide a representation which resemble
% is designed for efficient real-time rendering and therefore we 
% and it only aims at showing a structure that closely resemble the DNA rather than a stricly accurar
%goal is to depict a close repesentaion of the DNA rather than a scie
%does not depict a scientifically accurate representation of DNA structure
%With their method they are able to render entire amino-acid for a single initial per-vertex operation.
%With most The modeling of DNA fibre structure is 
% to be stored on the memory of graphics devices, for DNA strands are usually composed of very large number of individual bases.
% since the memory transfer between
%would much bigger because of the overly large number of individual  DNA strand.
%(Give example with micoplasma, and E.Coli)
% is two issues that would occur.
%But because of a very large number of individual nucleic acids the resu memory footprint 
%An approach similar to Lampe et al.[] could also be e
%Using this approach 
%We adapted a HiZ buffer culling approach but 
%In order to 
%
%*************************************************
%perform a series of look-up in the HiZ buffer and compare the depth values.
%To minimize the number of look-up the que
%They use a bounding
%To lower the cost of the occlusion culling process they reduce the bounding
%, a bounding volume is often used instead of the entire geometry.
%Upon rendering of the bounding object the resulting depth in the fragment program are then compared with the input depth occlusion texture 
%and if the fragments are deeper that those of the look-up texture this means that the object is hidden.
%Depending on the size of an object, the optimum resolution image will be used for the query to limit the number of read accesses.
%Grottel et al.[] presented an occlusion culli
% hidden molecules will not be processed and create overlap with visible geometries.
%For a given pixel this will results in
%This results in 
%The main bottleneck of this pipeline is located in the per fragment processing at the final stage of the rendering.
%The bottleneck of this pipeline is situated  
% with up to several billions atoms 
% the large quantities of spheres to render will cause 
%The bottleneck of our rendering approach is tied the large quantity of overlapping geometries that are renderer.
%An efficient way to reduce this computational load is to ensure that hidden molecules will not be processed and create overlap with visible geometries.
%Grottel et al uniform particiotning, but limited to finite spaces
%The rendering approach which me present relies to the 
%accumulated GPU-driver
%also causing a GPU-driver overhead for
%after a certain latency which is due to the processing in the graphics pipeline
%The queries are performed in serials which also causes a certain latency due the read-back
%The query resu
%an be read back to the application after a certain latency which is due to the processing in the graphics pipeline
%This method performs 
%against the depth buffer
%that internally implements occlusion culling.

%
%
%\textbf{Occlusion culling.}
%
%Fiber support
%
%These supporting structures are precomputed 
%  of protein structures rather than raw atomic.
%
% and may also occupy more memory space than the raw data
%
%other parts of the pipeline such as the simulation
%
%For far these
%
%the minimum requirement for a comfortable user experience is between 24 and 60 Hz on average for games, and is even higher than 60 Hz for VR content.
%
%, which is still out of reach for very
%
%
%, which additionally leaves little to no room for other type of computation such as animation or physics simulations.

%However, the minimum requirement for a comfortable user experience is between 20 and 60 Hz on average for games, and higher than 60 Hz for VR content, which is still out of reach for very large datasets as the state-of-the-art method is capable of rendering 10 billions atom at 4 fps, which additionally leaves little to no room for other type of computation such as animation or physics simulations.
%
%Moreover, the presented solutions were specifically designed for efficient rendering of proteins data only.
%None of the techniques mentioned above have proved to efficiently support other types of molecular structures that exhibit much more complex organization, such as lipid membranes, nucleic acids or fibers, which ought to be taken into account for a truer depiction of molecular landscapes.
%Indeed, the properties of these structures can represent a challenge, especially for dynamic data because the assembling blocks of these structures are considerably smaller and also more numerous than with protein data.
%Several work focus on the modelling and visualization of such structures, such as life explorer[] or lipid wrapper[].
%However, none of these tools feature a visualization method that has the ambition to support overwhelmingly large datasets such as entire cells and which we deem crucial to achieve interactive and explanatory visualization of molecular biology.
%Furthermore, macro-molecular elements are usually densely arranged inside compartments (see figure), which may results in serious occlusion problems when interactively exploring a dataset.
%This visualization challenge has not yet been explored in the context of molecular visualization although it is crucial to address it to improve the quality of the user experience.
%It is also important to mention that none of the presented method above has been integrated into an animation or game creation package, which makes impossible for content creators to use it is a practical scenario.
%This review of the literature clearly underlines the lack of an efficient and integrated solution that would:
%a) Allow real-time rendering of datasets up to the size of a single cell
%b) Support all type of molecular structures efficiently
%c) Implement efficient occlusion management
%d) Provide tools that are embedded with animation or game creation package for optimized collaboration with various actors of the illustration process.





%\section{Related Work}
%
%Our goal is to improve visual communication of molecular biology, and ultimately to promote interactive showcasing as a standard media for educating the masses about biology.
%Valuable data from computation biology is constantly produced by experts and is often publicly available. 
%It contains thorough description about how things look (structures) and how things work (processes), and we intend to make extensive use of this data to enable the next generation of scientific illustration.
%The visualization literature already comprises a few work that are going in a similar direction and we will distinguish between the related work related to structural visualization in the first section and follow-up with related work about visualization of biochemical processes.

%\textbf{Structures}
%
%Structural biology is the branch of molecular biology that focuses on studying the structure of macromolecular elements in order to better understand their function.
%Visualization is an important component of this discipline because atoms are arranged and assembled in 3 dimensional space and therefore a visual representation is very often required.
%Scientist are using different types of representation to illustrate molecular structures, and we will describe the most commonly used ones.
%The simplest representation is the sticks model, where each bonds are represented as a line and color coding is used to indicate the atom type at the line extremities or joints.
%A popular representation among structural biologists is the secondary structure or ribbon diagram, it is used to reveal properties of the proteins backbone such as sheets or helices.
%The molecular surface representation is used to show a continuous surface that closely surround atoms of a protein and that also close small holes between atoms that are not accessible by small solvent molecules.
%This method was first introduced to reveal information that is not salient enough with other types of representation, such as the presence of pockets and cavities buried in the protein structure and that can potentially host important reaction sites.
%In popular molecular visualization packages such as VMD[] or PyMol[], molecular surfaces are stored as polygon meshes, for the simple reason that meshes are widely supported by graphics APIs.
%Another representation which is commonly understood by a larger audience is the Van der Waals surface, which simply represent atoms as spheres whose radius corresponds to the atomic radius.
%Compared to molecular surfaces, the Van der Waals representation provides important information about atomic composition of proteins which is not clearly visible with molecular surfaces.
%The Van-der-Waals surfaces are usually represented as meshes, but because the surface features highly detailed asperities it often requires a high polygon count to obtain a decent mesh quality, and which may overload the rendering pipeline when a large number of proteins is displayed.
%Molecular surfaces are therefore a commonly used representation among illustrators for depicting large and complex scenes because they can easily import and render meshes with 3D animation packages, and also because surfaces meshes are more lightweight than Van der Waals meshes.
%BioBlender[], Molecular Maya[], ePMV[], are examples of plugins for animation packages that were specifically developed to ease the loading and rendering of molecular surface meshes.
%To improve rendering performances of highly detailed molecular structures, Tarini et al. introduced a novel visualization technique to render Van der Waals surfaces with a much lower polygon count than with surface meshes.
%
%
%
%The rendering method is inspired from 2D billboards, a concept commonly used in computer graphics and games, and consists of drawing camera-facing 2D sphere impostors rather than tessellated 3D spheres when rendering individual atoms, thus considerably reducing the polygon count.
%With their approach, they were able to interactively render large datasets (up to xxxk atoms) with very high quality details.
%This method inspired several follow-up works that address the challenge of the constantly increasing size of available datasets in molecular biology.
%Lampe et al. [8] pioneered real-time rendering of large-scale atomic data on consumer level hardware. 
%They extended the fast billboard-based approach introduced by Tarini et al. [19] by leveraging the geometry shader to instantiate entire atom-blocks rather than single atom, thus reducing the memory bandwidth usage and GPU driver overhead by invoking fewer draw operations. 
%Grottel at al. proposed to improve the rendering speed of large particle-based datasets by implementing occlusion culling to discard hidden particle chunks from the rendering pipeline, based on the depth information obtained in the previous frame.
%Lindow et al. [11] followed-up the work of Lampe et al. by using instanced rendering of entire protein structures instead. 
%For each molecule type, they precompute a 3D grid containing the atomic structure and which is stored on the GPU.
%Upon the drawing of a protein the bounding box is drawn first, then during the per-fragment operation rays are cast through the grid, in order to find the first atom which is hit by the ray.
%Falk et al. [3] further refined the method by introducing depth culling and level-of-detail for the grid structures to achieve faster rendering performance for even larger scenes.
%Up to this point, the rendering methods presented in the literature have reached unprecedented levels of performance, in terms of size of supported dataset and rendering speed.
%However, the minimum requirement for a comfortable user experience is between 20 and 60 Hz on average games, and higher than 60 Hz for VR content, which is still out of reach for very large datasets (10 billions atoms at 4 fps).
%Moreover, the presented solutions were specifically designed for efficient rendering of macro molecules only, such as proteins.
%None of the techniques mentioned above have proved to efficiently support other types of molecular structures that exhibit much more complex organization, such as lipid membranes, nucleic acids or fibers, which ought to be taken into account for a truer depiction of molecular landscapes.
%Indeed, the properties of these structures can represent a challenge, especially for dynamic data because the assembling blocks or these structures are considerably smaller and also more numerous than with protein data.
%Several work focus on the modelling and visualization of such structures, life explorer [] is a visualization software designed for interactive modelling and viewing of DNA strands, lipid wrapper[] is a tool designed to generate lipid membranes based on arbitrary meshes.
%However, none of these tools feature a visualization method that has the ambition to support overwhelmingly large datasets such as entire cells and which we deem crucial to achieve interactive and explanatory visualization of molecular biology.
%
%Moreover, macro-molecular elements are usually densely arranged inside compartments (see figure), which may results in serious occlusion problems when interactively exploring a dataset.
%This visualization challenge has not yet been explored in the context of molecular visualization although it is crucial to address it to improve the quality of the user experience.
%
%This review of the literature clearly underlines the lack of an efficient and integrated solution that would:
%a) Allow real-time rendering of datasets up to the size of a single cell
%b) Support all type of molecular structures efficiently
%c) Implement efficient occlusion management
%d) Provide tools that are embedded with animation or game creation package for optimized collaboration with various actors of the illustration process.

%----------------------
%Several molecular surface computation techniques have been developed, each one with their own drawbacks and advantages.
%SAS[] and Gaussian[] are easy to compute but offer less informative details.
%SES[] and MSS[] are more complex to compute and also provide more surface details which can facilitate the cavity and pocket exploration.
%----------------------

%\textit{and also because smooth surfaces have a much lower overhead than highly tessellated Van-der-Waals surfaces}
%While meshes are often used because of practical reason, they also have a significant computational overhead when featuring a high level of asperity details such as with SES or Van-der-Walls because of the large number of polygon needed to smoothly discretize a complex surface.
%In the visualization literature it exists a few techniques that were developed to overcome this limitation by using a ray-casting approach and grid-based supporting structures.
%Since the recent democratization of domestic and massively parallel computing processors (GPU) it has been possible to implement efficient SES computing and rendering methods [LBPH10,KGE11].
%These methods are able to render the SES for dynamic data sets of around 100k atoms interactively on current hardware.
%Subsequently, Krone et al. implemented a method allowing smooth rendering of Gaussian surfaces for large and dynamic molecular data based on a massively parallel GPU algorithm. 
%%Atoms are stored in a 3D grid, which allows fast accumulation of Gaussian density for each voxel.
%While their technique only supports Gaussian surfaces, which offer less details than SES, they are also able to render much larger dynamic datasets composed of several million atoms.
%Based on the idea that highly detailed molecular surfaces are only needed when closely observing a protein, Parulek et al. introduced the concept of continuous level-of-detail for molecular surfaces.
%They seamlessly transit from highly detailed (SES) to less detailed (Gaussian) surface rendering based on the distance to the camera.
%Because the most complex operation is only performed for a small region of the overall protein, this method provides faster rendering speeds while also reducing visual complexity caused by unnecessary surface details, in the context area.

%The trend in recent molecular surface visualization methods clearly leans towards faster and highly optimized GPU implementations.
%The supporting structures are three dimensional grids because operations performed on such structures can be easily parallelized, thus more efficient.
%The use of uniform spatial partitioning schemes however limits the overall size of the scene, as the complexity and memory usage increases exponentially as the resolution of 3D grid increases, which is why such techniques were not implemented in 3D animation packages and employed by scientific illustrators.
%To overcome this size limitation of the scene, De Hera Chomski[] implemented a CPU-based ray tracing software based on a bounding volume hierarchy (BVH) instead.
%The use of such acceleration structure enable real-time rendering of large and complex scenes, however dynamic data requires constant update of the BVH which adds additional complex work on top of the rendering and limits the real-time capability of the method.

% which is why illustrators often use smooth and simpler surface representations such as the Gaussian instead.

%\textbf{Processes}

%Modeling systems biology processes 
% calls for efficient visualization methods to cope with the complexity nature of the data resulting from the simulation.

%The principle of systems biology is to reproduce complex physiological processes \textit{in silico} in order to better understand how living organisms work.
%Firstly, the models are designed throughout descriptions of molecular interactions that are laid down in 2D reaction networks and digitalized.
%Subsequently, the models are used as input for computational simulations and finally, simulation results are used for further analysis and hypothesis verification.
%It exists a few popular visualization software that aim at connecting the modeling, simulation, and data analysis in a single framework to facilitate the task of biologists, such as CellDesigner[] TinkerCell[] or VCell[].
%These tools usually cover non-spatial models (kinetic modelling), except VCell which also supports the use of external particle-based simulation modules such as Smoldyn[].
%Although the simulation data may feature 3D particle trajectories, the framework do not include a visualization module for observing the behaviour of individual 3D particles, simply because it would have only very little value to most experts as they are more interested in studying changes in species concentration.
%However, in few specific cases, such as the study of signalling pathways for example, the 3D visualization of particle-based simulation results is thought to be informative to scientists that are interested in studying the spatial distribution of certain species over time.
%To a certain extent, this information could also have an informative value for the laymen because it depicts complex processes in the form of a 3D animation, similarly to an explanatory movie.
%Specific visualization tools where developed to produce 3D animations out of such particle-based simulations, supporting either playback of pre-computed data [CellBlender][Falk] or in-situ visualization of simulation computed in real-time [ZigCell].
%Naive visualization of the raw trajectory data, however, may results in an overly cluttered view due to the large number of elements moving in random directions, and it is therefore crucial to intuitively guide the viewer to ensure a maximum degree of clarity.
%Falk et al.[] added to the raw visualization the possibility to track single elements throughout time by tracing the trajectory of a particle and highlight the cascade of reactions which is relevant for the study of signalling pathways.
%Although previous works attempted to improve the raw visualization of particle-based simulation with useful overlaid information, there is still left to address the grand challenge which is due to time-scale discrepancies between entire processes and individual reactions, and which is described as follows: 
%On the one hand, observing the particle-based simulation at a slow pace to be able to keep track of individual elements and see interactions, would require hours to explore the entire process.
%On the other hand, observing the simulation in fast-forward would shorten the viewing length but it would become impossible to observe important reaction events because of the very fast pace at which elements would be moving.
%Furthermore, the real-time limitations of particle-based simulation tools still has to be addressed in order to deliver a smooth educational user experience.
%Indeed, the simulation of particle-based systems is very demanding in terms of computation and is usually precomputed prior to the visualization, which prohibit online interaction with the simulation parameters and real-time exploration of multiple simulation scenario.
%The most-optimized simulation tools leverage the power of GPU computing to speed-up the computation and enable \textit{in-situ} visualization [ZigCell].
%However, even most optimized particle-based simulation methods are still not able to compute complex models in a reasonable amount of time to enable a smooth and interactive experience.
%Other modeling methods, such as kinetic modeling, do not feature 3D dimensional data but are much faster to compute, and therefore quantitative information could also be used to interactively drive 3D animated particle data for explanatory purposes.

%***********************************************************
%Say that the next step-up in scientific illustration is interaction/real-time graphics.
%
%Talk about the currently existing interactive things (Games, tools, installation, VR/AR).
%
%Talk about the importance of interactivity (Faster content creation, non deterministic story telling).
%
%Talk about the limitation is terms of time needed for asset creation.
%
%Talk about the vision, which is an interactive platform that would utilize the data available to  
%***************************************************************


%-----------------------------------------------

%\textbf{Towards a dynamic and interactive model of a cell (E.Coli)}
%
%\textbf{Requirement analysis}
%
%The heart of this thesis is joining together structural and functional data, and the introduction of interactive techniques for the production of biological illustrations.
%
%We see the introduction of interactive illustration as two fold:
%
%.Gain time in producing illustration (render/animation times)
%.Offer a more engaging user experience (multiple scenario exploration VR)
%
%%Dealing with mutliple local scales
%The challenge in rendering lies in rendering multiple scales when dealing with atomic level data.
%
%%Dealing with mutliple temporal scales
%The challenge in animation lies in how to simultaneously show processes operation at different time scales.
%
%%Dealing with interaction and scenario changes
%The challenge in interaction lies in the fact that simulation of spatial data is very slow
%
%%Dealing with occlusion
%Large amount of data which need to be rendering when observing data o

%-----------------------------------------------

%Illustration help to understand but they are time consuming (gathering data, and realization).
%
%Computer graphics programs already help illustrators to accelerate their work (Maya, Cinema4D)
%
%But there is still a lot of work to do.
%
%Constant improvement in game technologies in often applied across field to accelerate the artists job in the movie industry (real-time simulation, real-time rendering, interaction)
%
%This help scientific illustrators too, but often they are using dedicated tools which are not mainstream and therefore only very few process is made for them.
% 
%Structure:
%
%Dealing with Large Amount of Data 
%
%Dealing with Multiple Scales.
%
%Dealing with Stochasticity / Introducing interaction
%
%Dealing with Occlusion.

%Part C the visualization (occlusion)
%Part E spatial navigation 
%Part F temporal navigation 
%Part D scenario interaction 

\section{Using Computation Data for Storytelling}

\section{Efficient Rendering of Large Structures}

\section{Efficient Spatial Composition and Occlusion Management}

\section{Conclusion}

%Since \LaTeX\ is widely used in academia and industry, there exists a plethora of freely accessible introductions to the language.
%Reading through the guide at \url{https://en.wikibooks.org/wiki/LaTeX} serves as a comprehensive overview for most of the functionality and is highly recommended before starting with a thesis in \LaTeX.
%
%\section{Installation}
%
%A full \LaTeX\ distribution\index{distribution} consists of not only of the binaries that convert the source files to the typeset documents, but also of a wide range of packages and their documentation.
%Depending on the operating system, different implementations are available as shown in Table~\ref{tab:distrib}.
%\textbf{Due to the large amount of packages that are in everyday use and due to their high interdependence, it is paramount to keep the installed distribution\index{distribution} up to date.}
%Otherwise, obscure errors and tedious debugging ensue.
%
%\section{Editors}
%
%A multitude of \TeX\ \glspl{texteditor} are available differing in their editing models, their supported operating systems and their feature sets.
%A comprehensive overview of \glspl{texteditor} can be found at the Wikipedia page  \url{https://en.wikipedia.org/wiki/Comparison_of_TeX_editors}.
%TeXstudio (\url{http://texstudio.sourceforge.net/}) is recommended.
%
%\section{Compilation}
%
%Modern editors usually provide the compilation programs to generate \gls{pdf} documents and for most \LaTeX\ source files, this is sufficient.
%More advanced \LaTeX\ functionality, such as glossaries and bibliographies, needs additional compilation steps, however.
%It is also possible that errors in the compilation process invalidate intermediate files and force subsequent compilation runs to fail.
%It is advisable to delete intermediate files (\verb|.aux|, \verb|.bbl|, etc.), if errors occur and persist.
%All files that are not generated by the user are automatically regenerated.
%To compile the current document, the steps as shown in Table~\ref{tab:compile} have to be taken.