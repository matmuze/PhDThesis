\newacronym{ctan}{CTAN}{Comprehensive TeX Archive Network}
\newacronym{faq}{FAQ}{Frequently Asked Questions}
\newacronym{pdf}{PDF}{Portable Document Format}
\newacronym{svn}{SVN}{Subversion}
\newacronym{wysiwyg}{WYSIWYG}{What You See Is What You Get}

\newglossaryentry{texteditor}
{
	name={editor},
	description={A text editor is a type of program used for editing plain text files.}
}

\chapter{Abstract}

This is where the first chapter begins...

\chapter{Related Publications}

This is where the first chapter begins...

\chapter{Overview}

%\textbf{Importance of visualisation in the physiology}
%Physiology describes how livings organism work, and it spans across multiple scientific fields.
%It is therefore important to be able to communicate scientific advances efficiently between experts with various scientific background.
%Additionally, there is also a growing interest from the general audience to understand how their own body function.
%Explaining such complex processes is usually very challenging without a supporting illustration.
%Although some illustrators are still doing hand-made illustrations, many of them are using tools inspired from movie production to accelerate their work.
%Despite that, modeling a single scenario is still very time consuming (gathering data and realization).
%Moreover, illustrations are usually static, (still images and movies) and do not offer much interactivity.

%Printed illustrations have the clear advantage to be easily accessible by the viewer, via a school textooks, scientific magazines, encyclopedia, or simply via the web. 
%To being with this ambitious enterprise it is necessary to starting studying how processes work on the atomic level, the smallest level which we  understand to this day.
%It also exists different types of supports for visual communication other than still images, such as animated movies (animated and non-interactive) and educational games (animated and interactive).
%Due to the popularity of digital effects used in the movie industry over the last decades, 3D animation packages and online training became widely available thus popularizing the use of these tools by scientific illustrators.
%The storytelling is a key element of an illustration as it is responsible of conveying the core message.
%Animated content is very powerful in illustration because it efficiently engages the viewer into the story (stupid comparison of people preferring movies to books).
%Due to the , 3D animation packages and online training became widely available thus popularizing the use of these tools by scientific illustrators.
%which became widely available thanks to the popularity of digital effects used in the movie industry over the last decades
%In order to understand how we work we must first understand the complete cascade of events down from atomic level and up to microscopic and macroscopic levels.

\section{Introduction}

\textbf{Importance of Visualisation in Biology} \\
Biochemistry lies at the root of complex biological systems that describe the machinery of life, and in order to understand how we work we must first understand the complete cascade of events that is taking place at the atomic level.
Because biological systems spans several scales and scientific fields, such as biology, chemistry, mathematics, or medicine, it is crucial to communicate advances in biochemistry efficiently between experts with various scientific background.
Moreover, there is also a growing interest from the general audience to understand how their living organisms work.
Visual communication is undeniably an efficient way to educate a non-expert audience about the functioning of physiological processes.
A quick glance at physiological textbooks is enough to realize that they would be close to useless without any illustrations.
Illustrations, such as the ones made by David Goodsell, are often used to illustrate such textbooks.
The illustrator likes to depict entire sceneries on the mesoscale levels, such as ...(figure X) that would be impossible to observe otherwise in such detail using current optical instruments.
His paintings rightfully balance scientific accuracy and clarity, which makes them very popular because they are accessible to a large audience. 
The realization of such illustrations, however, is very laborious and also demands highly skilled individuals.
The first step of the creation process consists of gathering knowledge from the scientific literature in order to thoroughly understand the process that is to be depicted.
This task demands a strong understanding of biology as scientific articles are intended to be read by experts and peers.
Based on this knowledge, the illustrator will decide how to compose the scene, i.e., which macromolecular structures should be present, where should they be located, in which quantities, and what behaviour should they exhibit.
The second step of the creation process is the drawing. 
It is important not to confuse the work of a scientific illustrator with the work of an artist.
Although they both aim at conveying a message or an idea, the artist has the freedom to hide his message behind an abstraction curtain in order to challenge the viewer.
On the contrary, an illustrator has to convey a message as clearly as possible in order to expose scientific concepts to an uninformed audience.`
This concretely means that the illustrator is bound to a set of logical guidelines in terms of composition, lighting, color-coding or storytelling.

While some illustrators prefer working with paper and pencil or 2D composition software such as Photoshop, the new generation of illustrators grew with 3D rendering and animation packages such as Maya, Cinema4D or Blender, made mainstream by the popularization of digital effects in the movie industry.
The use of such computer aided design tools greatly facilitates the drawing operation of three dimensional data.
Perspective and lighting effects, for instance, are automatically handled by the software, thus leaving artists more time to work on other aspects such as material design, composition, or post-processing.
Since less time is spent working on single images it is also less cumbersome to produce animated stories.
Consequently, 3D animation  became an increasingly popular means of visual communication to depict the machinery of life, as it is a great way to engage the viewer into a storyline.
One notorious animated educational material is "The Inner Life of the Cell" realized in 2008 by the XVIVO medical illustration studio and appointed by Harvard University.
This short animated video beautifully depicts in few sequences the logical cascade of events that describe complex biochemical processes of a living cell.
The structures of the different actors are based on real structural information available from public databases and their behaviour based on the most recent knowledge of cell biology.
Furthermore, environments surrounding each event is also accurately depicted to provide important information about location and scale.
This masterpiece of scientific animation took the whole team of experts 14 month to produce, which is a good average production time for a 5 to 10 minutes educational material of this quality.
Unfortunately, on top of being time consuming, the production of such films is also very costly, which somehow limits the accessibility and availability of such visualization.

%Over the last years, the net revenues of the computer game industry have largely outperformed those of the movie industry, which was not the case a few years ago.
%This trend clearly indicates the growing interest of the public in interactive entertainment and  storytelling. 
%Moreover, the recent emergence of a new generation of virtual and augmented reality hardware such as the Occulus Rift, HTC Vive, Microsoft Hololens, are now paving the way towards the next generation of computer games which promise to be even more immersive, realistic and engaging.
%Given the raising interest of the general audience in this type of interactive experience we can imagine that this could be hugely effective for edutainment and scientific dissemination of cell biology.
%By embedding the subject into the presented content, he becomes an actor of the virtual world and his attention naturally increases. 

%\textbf{Here break the read thread between games, and introduce the idea of entirely virtual biological systems.}

Another type of media which has a great potential for educational purposes is interactive applications.
Compared to movies, interactive titles, such as computer games, are able to keep the player engaged with educational content using the traditional reward system present in many computer games.
Immune Attack[] or Sim Cell[] are two famous examples of edutainment titles whose goal is to reveal the functioning of living cells through accomplishment of actions that are part of physiological processes.
Promising new VR devices have also emerged over the last years, and are now paving the way for more exciting and engaging user experiences that could have a great educational outreach.
However, the production of high quality interactive content, similarly to animated films, is also a lengthy and costly enterprise, as technicians and programming experts are also needed in addition to the team.
Interactive applications may also have an educational purpose without necessarily introducing gameplay mechanisms or score-based rewards. 
A good example is interactive maps applications, such as Google Earth[].
Unlike static maps, these applications enable on-demand access to specific information.
Through a set of 2D interactions such as zoom, rotate and pan, or 3D interactions such as tilt, the user is free to navigate to whichever part of earth that he deems interesting.
It also features multiple zoom levels from planets down to the size of building, houses or even cars.
Another strong advantage of the platform is crowd-based collaboration.
Three dimensional data obtained from scans of entire cities for instance can be provided by the municipalities and added to the platform for in-depth city architecture exploration.
Finally, the platform is not only bound to static representation of earth, dynamic data such as traffic or meteorology provided by third party applications can also be plugged and included to the platform.
The final outcome is a system that enables omniscient and three dimensional observation of the planet and its dynamics based on available data.
The educational outreach of this software is undeniable as it transcend all types of media previously used and provides unconstrained access to multiple types of information at once. 

To our knowledge, the concept of reproducing an observable virtual environment as such, has not yet been transposed to the level of an entire cell.
In order to achieve this enterprise one would need access to important data such as the three dimensional structures of macromolecules and greater ensembles that form the compartments and various organelles of the cells.
As cells carry multiple functions expressed in biological systems, reaction networks between micro and macromolecules, as well as dynamic data, such as molecular reactions and migration patterns also would be needed to digitally reproduce a truly observable living cell.
Fortunately, a large amount of biological knowledge is publicly available via online databases.
The Protein Data Bank[], for instance, is a project that aims at regrouping every known protein structures in large public data base.
Ecocyc[], is another project that aim at gathering extensive procedural descriptions of the biological systems that are ongoing in the E. Coli bacterium.
Based on these descriptions, biologists have managed to simulate processes of the entire bacterium at once on a super-computer and have also made the results available.
Similarly to satellite data, or traffic data in Google Earth, the data present in these databases are steadily updated with most recent scientific knowledge by a large crowd of researchers, for as long as the projects are maintained.
Despite the large quantity of data available, there is yet no solution that could generate a comprehensible digital cell based on this data, and that would be both dynamic and multiscale.
As the production of animated and interactive educational content is often prohibitive, we envision that such interactive platform would be a great mean to keep layman audiences and multidisciplinary experts informed about the latest knowledge of cell biology.

%\textbf{Here break the read thread between games, and introduce the idea of entirely virtual biological systems.}
%
%analogy to Google Earth (Virtual Earth)
%, not static maps, on demand access to specific inforation.
%Not a game, not movies, something new different concept.
%Google maps 
%
%Crowd based participation on structures...
%Structures vs dynamics of traffic for instance.
%Increasing incorporation of dynamics phenomena.
%Unconstrained access,
%
%What is needed for applying same concept to cell level ??
%What are structures, envrionements, actors, protein energy organelles reaction networks.
%
%(A large amount) these information is already available (PDB, cellpack, computational models)
%And is also steadily updated.
%
%(http://ecocyc.org/) Try to gather multiple of information in one place (Wiki)
%\textit{EcoCyc is a scientific database for the bacterium Escherichia coli K-12 MG1655. The EcoCyc project performs literature-based curation of the entire genome, and of transcriptional regulation, transporters, and metabolic pathways. }
%
%The data ----> google earth



%Another type of media which has a great potential for educational purposes is computer games.
%Immune Attack[] or Sim Cell[] are two famous examples of edutainment titles whose goal is to reveal the functioning of living cells through accomplishment of actions that are part of physiological processes.
%These titles are based on the traditional reward system present in many computer games and that ensures to keep the player engaged with educational content.
%The motivation of a player, however, does not always have to be solely driven by the high-scores.
%We can observe a recent trend among AAA game titles towards interactive storytelling rather than pure gameplay.
%Those titles usually feature cinematic sequences, interleaved between interactive sessions.
%The resulting user experience then blends animation and interaction, and the player's motivation is thus driven by his curiosity to unravel the storyline rather than high-scores.
%We envision to translate this concept to dissemination of sciences in order to produce more engaging user experiences that would raise awareness about cell biology.
%Interactive rendering would also enable new types of action for user-driver exploration that would not be possible otherwise with movies, such as camera navigation, selective visibility of certain elements to reveal important hidden structures, or interactive change of biochemical properties to modify the course of the scenario.
%Additionally, the recent emergence of highly capable virtual reality headsets promises the next generation of interactive experiences to be even more immersive and engaging.
%This could encourage even more people to explore and interact with virtual educational content.
%
%The production of high quality interactive content, however, is often more constrained than the production of offline animations.
%Indeed, due to fast framerates needed in computer games (20 to 60 fps, and even more for VR) it is difficult to interactively render entire complex environments that we may see in movies, which could affect the overall educational impact. 
%Additionally, the creation team also requires more people, e.g. computer programmers, which could increase the production costs and times compared to movies.
%Given that the creation of a high quality explanatory videos about cell biology is already a very lengthy and costly enterprise, it is clear that new tools and technologies would have be developed to enable the creation of next generation of interactive user-experiences that would keep audiences informed about cell biology. 
%
%Firstly, it is important to improve the real-time rendering capabilities of interactive content creation tools, in order to quickly display large and complex structures on par with those seen in animated movies.
%Secondly, is it also crucial to streamline the content creation process in order to reduce production times and costs.
%Computational biology generates data which contains valuable information about the structures of macromolecular elements and ensembles which compose molecular landscapes.
%It also comprise procedural descriptions of dynamic biological systems, obtained via computerised simulations.
%Our idea is to combine these two aspects to virtually reproduce an observable dynamic biological system in three dimensions.
%Animations would then be automatically generated by scientific data, thus saving illustrators countless hours of manual composition and animation.
%Ultimately, we envision this concept to lead to the popularization of digital and educational material and thus to improve visual communication to layman audiences and across scientific disciples.


%In biology the cost of wet lab experiments is significantly higher than the cost of computer-based simulations.%
%Such simulation have a great value because they provide important insight about the functioning of a system. %
%Over the last years the use of computer-based simulation have significantly increase in biology.
%\textit{The goal of a model is to approximate a given process, a complete and accurate model might simply too complex to describe of to simulate, also some aspects may sometimes be unknown}%
%\textit{Isolate a single part of the entire machinery to easily study its mechanism.}%
%These experiments are widely criticized because often deemed too approximative due to human knowledge or computational limitations.

\section{Background and Related Work}

\textbf{Computational Biology to Assist Scientific Illustration}\\
In biochemistry, it exists two distinct experimental protocols, respectively called dry and wet laboratories.
Wet laboratories are where chemical agents are physically manipulated and then observed.
Dry laboratories are where computational or mathematical methods are employed for the modelling and analysis of biochemical processes. 
Over the last decades, \textit{in-silico} experiments (dry laboratories) have significantly increased due to the development of new software and the decreasing costs of super-computers.
%Due to computational or human limitations, it may be often impractical to accurately simulate a given process in its entirety.
Despite being often criticized for being too approximative, dry laboratory experiments represent a valuable source of information for researchers nonetheless.
In 2013 Martin Karplus, Michael Levitt and Arieh Warshel were awarded the Nobel prize in Chemistry for their work on theoretical modelling for complex chemical system.
Their work highlight the importance of theoretical modelling as a tool to complement experimental techniques as wet-lab experiments are usually complex and expensive to conduct.
The analysis of theoretical modeling brings researchers the necessary guidance to formulate new hypothesis which can be later on verified in wet laboratories, this saving the time and money needed to run too many wet lab experiments.
As a result of the increasing popularity of dry lab experiments, a significant amount of data has already been gathered and produced.
Data is often stored in digital format and may be shared to other peers via online databases.
Structural biology and Systems biology are branches or molecular biology that both heavily rely on computational method.
Structural biology informs us about how things look, i.e., what is the atomic structure of a protein, while systems biology informs us about how things work, i.e., how micro and macromolecular interacts and to form a given physiological process.

%\section{Related Work}
%
%Our goal is to improve visual communication of molecular biology, and ultimately to promote interactive showcasing as a standard media for educating the masses about biology.
%Valuable data from computation biology is constantly produced by experts and is often publicly available. 
%It contains thorough description about how things look (structures) and how things work (processes), and we intend to make extensive use of this data to enable the next generation of scientific illustration.
%The visualization literature already comprises a few work that are going in a similar direction and we will distinguish between the related work related to structural visualization in the first section and follow-up with related work about visualization of biochemical processes.

\subsection{Visualization of Biological Structures}

Structural biology is concerned by the structure of biological macromolecules (proteins and nucleic acids), and the relationship between molecular structure and function.
Data acquisition methods such as x-ray crystallography are commonly used to read in details the atomic structure of proteins, i.e, the positions or atoms, their type and the type of bonds between them.
Acquired atomic structures are often stored in digital files and shared via public data bases such as the Protein Data Bank[] to facilitate collaboration among biologists.
This information is then processed to decrypt underlying important structural information and also used to run molecular dynamics (MD) simulations, that aims at reproducing atomic interactions and forces to observe the actual behaviour of macromolecules over time.
Visualization is an important component of this discipline because atoms are arranged and assembled in 3 dimensional space and therefore a visual representation is often required.
Biologists developed several types of representation to illustrate molecular structures, and they are also supported by mainstream visualization packages such as VMD[] or PyMol[].
The simplest representation is the sticks model, where each bonds are represented as a line, and color coding is used to indicate the atom type at the line extremities or joints.
The Van der Waals (VdW) surface, is probably the most commonly understood representation and simply shows atoms as spheres whose radius corresponds to the atomic radius.
A popular representation among structural biologists is the secondary structure or ribbon diagram, it is used to reveal properties of the protein backbones such as sheets or helices.
Finally, the molecular surface representation is used to show a continuous surface that closely surround atoms of a protein and that also close small holes between atoms that are not accessible by small solvent molecules.
This method was first introduced to reveal information that is not salient enough with other types of representation, such as the presence of pockets and cavities buried in the protein structure and that can potentially host important reaction sites.
In scientific illustrations the shape of a protein is an important aspect to convey as it is tightly related to its function, and therefore the surfaces or VdW representations are often preferred and are also easier to understand.
Furthermore, VdW spheres and molecular surfaces can easily be stored as polygon meshes which are supported by 3D animation packages.
BioBlender[], Molecular Maya[], ePMV[], are examples of plugins for animation packages that were specifically developed to ease the loading and rendering of molecular surface meshes.

X-ray crystallography is limited in a sense that it is not capable of capturing large and complex structures such as organelles, viruses, or cells, in their entirety.
Electron microscopy imaging, on the other hand, still does not offer enough resolution to capture individual atoms which make the segmentation task between proteins extremely challenging.
So far, only little is known about spatial arrangement of proteins that form greater structures and their manual modeling would be a cumbersome and time-consuming task.
To fill the mesoscale gap between atoms and cells, scientists from the Scripps Institute in San Diego have developed cellPACK[], a tool to procedurally construct large mesoscale structures, such as viruses, or entire cells at atomic resolution.
cellPACK incorporates the most recent knowledge obtained from biology to generate these models such as proteins structures obtained from crystallography, concentrations and spatial distribution observed \textit{in vitro}, and 3D shape of compartments acquired from electronic microscopy.
They summarize all this data in structural descriptions which they call a recipe, and which is then used as input to generate entire models of viruses and cells via a packing method based on collisions constraints.
Their packing algorithm progressively inject molecules in a 3D region and they use a spatial partitioning scheme to detect overlapping structures and find an appropriate location for incoming shapes.
As an output their tool generates a list which contains the position, rotation, and type of all the proteins that compose the organism.
Additionally their method also supports packing of fiber data such as DNA or RNA and is stored as control points in the resulting file.
The initial goal of cellPACK was to generate valid protein ensembles that forms organisms, and that also comprise atomic data in order to serve as input for large-scale molecular dynamics simulation.
Additionally, the generated structures can also be loaded in 3D rendering and animation packages for illustration purposes.
%, thus preventing illustrator to manually place and arrange proteins when depicting a larger protein ensemble.
These large models are highly valuable to us, as they comprise complex data that would have to be modeled manually otherwise, thus compromising the production of illustrative content.
They are also publicly available and can be easily updated with the most recent knowledge of cell biology.
However, the overwhelmingly large number of elements that compose these mesoscale structures begin to truly challenge animation packages that were not design with such constraints in mind.
While it is still possible to render still images in very high quality, real-time visualization of these models is simply not possible, even with simplified meshes. 
This affects the productivity of those who create the models, as well as those who are using it for illustration purposes and it also compromises the transition to the next generation of interactive scientific illustrations.

Although the polygon mesh is currently the most commonly used shape representation supported by animation packages and game creation software, it might not always provide the best performances for large and complex datasets.
Indeed to render highly detailed information meshes require an overwhelmingly large number of polygons which can stress the rendering pipeline and video memory usage.
To keep up with the increasing size of atomic datasets visualization experts developed new cutting edge techniques which do not rely on mesh data.
Tarini et al.[] introduced a novel visualization technique inspired from 2D billboards, a popular concept in computer games.
The technique consists of drawing camera-facing 2D sphere impostors rather than tessellated 3D spheres for rendering individual atoms.
As a result, to render a structure which comprise 1000 atoms only 4000 vertices would then be needed, which is rather low for the resulting image quality.
With their approach, they were able to interactively render large datasets (up to xxxk atoms) with very high quality details at a much lower cost than meshes.
Shortly afterwards, Lampe et al. [8] extended the billboard technique by leveraging the GPU rendering pipeline to reduce memory bandwidth usage and GPU driver overhead. 
Grottel at al. proposed to improve the rendering speed of large particle-based datasets by implementing occlusion culling to discard hidden particle chunks from the rendering pipeline, based on the depth information obtained in the previous frame.
Hence, only the sphere impostors that are garanteed to be visible will be processed by the graphics pipeline, thus increasing rendering performances greatly for very dense datasets.
Lindow et al. [11], subsequently presented a novel approach which is rely on ray-casting instead.
For each protein structure they store the individual atoms in small and fitting 3D grids and upload the protein grid on the video memory.
Upon the rendering they first draw the bounding box of the grid, and subsequently, in the per-fragment operation they cast ray for each single fragment in order to find the first hit with the atoms.
Their method supports rendering of very large structures with up to xxx atoms.
Mesoscale landscapes usually feature a high number of individual proteins that share the same structure.
In order to spare video memory usage which is usually restricted in size, they also use the principle of instancing, popular in computer games.
Instead of storing every single atoms on the video memory, they only upload the position and rotation of individual proteins to the video memory and upload each unique protein structure only once.
Falk et al. [3] further refined the method by introducing depth culling similarly to Grottel et al.[] and used level-of-detail for the grid structures to reduce computing for proteins that are located far away from the camera.
They reported being able to render large datasets representing cytoskeleton of a cell, with up to xx atoms at xx fps.
While the presented methods only support the VdW representation, a few techniques were also developed to improve the rendering of large and highly detailed molecular surfaces using GPU ray-casting and efficient supporting structures instead of meshes[][][]. 
However, none of these surface-based methods is yet able to compete in terms of performance with the most recent VdW methods which we previously presented .

\subsection{Visualization of Biological Systems}

Systems biology is the branch of biology concerned with computational or mathematical modeling of complex biological systems.
The organization of biological systems spans several scales; on the level of single cells they typically describe signalling or regulatory functions of living cells, such as energy production, gene expression, and ability to divide or die.
Such systems consists of reaction network between molecular agents such as enzymes, metabolites, or proteins, also known as pathway.
Based on the pathway description, scientists reproduce the dynamics of a system \textit{in silico}, via simulation tools, and observe the changes in species concentration over time.
The results of the simulation are then further analysed to predict and understand how these systems change over time and under varying conditions, and potentially develop solutions to health issues.
The complex reaction networks are usually described with a custom markup language, such as SBML[], and used as input for the simulation tools.
Similarly to protein structures the system descriptions are often shared with peers via public online databases[].
Biologists have developed several methods to simulate the dynamics of a system.
Depending on their modus operandi the modeling approach can either be deterministic or stochastic.
Models may also feature spatial information or be purely quantitative. 

Quantitative modeling (or Kinetic modeling) relies on the use of differential equation systems to compute the species concentrations at a given time and is therefore deterministic.
Results only vary according to the initial conditions such as concentrations and reaction rates that are predefined in the model.
Additionally, the models may also feature spatial information such as compartmentalization of species.
Quantitative was the first modeling method introduce and still remains very popular among system biologists because it is reliable and computationally inexpensive.
%A typical visual output for this type of simulation is a time-concentration plot.
Another type of modeling is agent-based modeling.
This method completely differs from the strictly mathematical approach used in Kinetic modeling.
It aims at reproducing the original reaction-diffusion behaviour of biochemical agents in three dimensional space and is therefore stochastic.
This technology was primarily developed to simulate and understand complex migration pattern among animal or human populations.
The concept was then transposed to study the behaviour of chemical species as more capable computer hardware became available and affordable.
With agent-based modeling, actors of systems are virtually represented as a 3D point in space and subject to constant random motion based on diffusion speeds observed in vitro.
New elements are introduced or removed according to individual reaction events.
Reaction events are triggered based on local proximity of potential reaction partners and reaction probability based on the reaction rates observed in-vitro.

It exists a few popular tools that aim at connecting the modeling, simulation, and data analysis in a single framework to facilitate the task of biologists, such as CellDesigner[] TinkerCell[] or VCell[].
These tools usually cover non-spatial models (quantitative modelling), except VCell[] which also supports the use of external agent-based simulation modules such as Smoldyn[].
At this stage, scientists studying these models have very limited ways to see how these mathematical models of physiology behave.
They can interact with the model by specifying input parameters to the simulation and the resulting visualizations are often time-concentration plots.
Even when the simulation method produce potentially interesting 3D trajectory data, these tools will favour highly abstracted visualizations which only experts can understand.
Such a visual form is hard to relate to what is visually observed in wet-lab experiments. 
In interdisciplinary physiological sciences this might hamper communication of results. 
However, the underlying data present in the models contains thorough dynamic descriptions of how these biological systems work.
These models informs us about the species present in a system, their quantities, location, diffusion speed, reaction partners, and reaction rates.
When associated with corresponding structural information this data could potentially to digitally reproduce and illustrative and dynamic model of a cell.
Biology, medicine, and other sciences can strongly profit from a visualization of physiology in order to gain, verify, and communicate the knowledge and the hypotheses in this field.
%Additionally, dynamics simulations, when computed along with the visualization could enable online changes of simulation parameters, such as species quantities or temperature, and directly observe how it would affect the system.
While the visualization of spatial trajectory data is often not relevant for the study of metabolic pathways, in specific cases, such as signalling pathways for example, such visualization might be informative to scientists that are interested in observing the spatial distribution of small signalling molecules overtime.
Few specific tools feature three dimensional visualization of particle trajectories obtained from agent-based simulation results.
CellBlender[] is a software conceived as a plug-in for the 3D animation package Blender, and which allow model design and visualization of particle-based models computed with MCell[].
%Via the user interface, it is possible to manually setup the model parameters, which are then fed to the external simulation module.
The cell compartments of a given model are represented as 3D meshes and can be modeled or loaded via the Blender interface.
Via the custom interface of the tool, expert users can specify the models parameters such as the species types, initial quantities, and diffusion speed.
MCell also supports 3D and 2D diffusion models for the particles.
3D diffusion is applied to elements diffusing freely inside a volume, while 2D diffusion is applied to elements that are embedded in a membrane and only diffuse along the compartment surface, such as channel proteins.
Users must then input the reactions of the model by specifying the participants, the products and the reaction probability.
Particles diffusing in 3D are also able to diffuse outside their initial compartment, and these crossing events must also be defined.
The user interface also features a multitude of advanced parameters to fine tune the modeling.
Finally, the user must specifies the duration of single step in nanosecond, and the desired number of steps. 
The duration of one simulation step will determine the precision of the simulation.
MCell then runs the computation offline based on the models properties setup in CellBlender, and produces large files that contain trajectory data for each single particle and for the given number of simulation steps.
%An additional file is also produced and contains the list of all reaction events, including the ID of participating elements, the reaction location and the corresponding time step.
The trajectory data is then converted to a key-frame particle animation format which is readable in Blender.
The simulation may then be played back for real-time exploration or rendered in movies.
Additionally, it is also possible to use custom meshes to visually encode the species type.
%The simulation approach, however, does not take into account the shape of the molecular structures, which are represented a simple 3D points, and thus the visualization of particle data using custom protein meshes will result in unwanted overlapping artefacts.
%To a certain extent, this information could also have an informative value for the laymen because it depicts complex processes in the form of a 3D animations.
%The viewing of actual three dimensional molecular interactions, such as the ones observed in scientific animations, could then be used as a mean to automatically generate expressive illustration of the simulated system.
Such trajectory data could potentially be used as such, to digitally reproduce the functioning of entire cells.
The resulting visualization would thus have an important informative value as it depict complex biological systems in the form of 3D diffusion and reaction animations embedded in their molecular environment.
A naive visualization of the raw trajectory data, however, may often results in an overly cluttered view due to the large number of elements randomly moving in every directions.
Although the display of trajectory data is valuable to expert users, it is almost incomprehensible for non-experts viewers.
Therefore, it is crucial to provide guidance to ensure that the underlying information, i.e., which elements react with each others and in which order, is perceived by the viewer.
Falk et al.[] proposed to enhance the playback particle trajectories with additional overlaid information to trace the history of individual particles, such as trajectory and previously undergone reactions.


%\subsection{Limitations of Related Work}
%
%So what, our vision is still not done.
%
%No real-time performace, only proteins
%No occlusion management
%
%Time scale discrepencies
%No real-time preformance, plus lack of camera guidance.
%
%****************
%
%
%Up to this point, the rendering methods presented in the literature have reached unprecedented levels of performance, in terms of size of supported dataset and rendering speed, thus enabling real-time rendering of large mesoscale models created with cellPACK[].
%However, the minimum requirement for a comfortable user experience is between 20 and 60 Hz on average for games, and higher than 60 Hz for VR content, which is still out of reach for very large datasets as the state-of-the-art method is capable of rendering 10 billions atom at 4 fps, which additionally leaves little to no room for other type of computation such as animation or physics simulations.
%
%Moreover, the presented solutions were specifically designed for efficient rendering of proteins data only.
%None of the techniques mentioned above have proved to efficiently support other types of molecular structures that exhibit much more complex organization, such as lipid membranes, nucleic acids or fibers, which ought to be taken into account for a truer depiction of molecular landscapes.
%Indeed, the properties of these structures can represent a challenge, especially for dynamic data because the assembling blocks of these structures are considerably smaller and also more numerous than with protein data.
%Several work focus on the modelling and visualization of such structures, such as life explorer[] or lipid wrapper[].
%However, none of these tools feature a visualization method that has the ambition to support overwhelmingly large datasets such as entire cells and which we deem crucial to achieve interactive and explanatory visualization of molecular biology.
%Furthermore, macro-molecular elements are usually densely arranged inside compartments (see figure), which may results in serious occlusion problems when interactively exploring a dataset.
%This visualization challenge has not yet been explored in the context of molecular visualization although it is crucial to address it to improve the quality of the user experience.
%It is also important to mention that none of the presented method above has been integrated into an animation or game creation package, which makes impossible for content creators to use it is a practical scenario.
%This review of the literature clearly underlines the lack of an efficient and integrated solution that would:
%a) Allow real-time rendering of datasets up to the size of a single cell
%b) Support all type of molecular structures efficiently
%c) Implement efficient occlusion management
%d) Provide tools that are embedded with animation or game creation package for optimized collaboration with various actors of the illustration process.
%
%Although previous works attempted to improve the raw visualization of particle-based visualization, there is still left to address the several grand challenges such as occlusion management for dense scenes or the issues that are due to time-scale discrepancies between entire processes and individual reactions, and which is described as follows: 
%On the one hand, observing the particle-based simulation at a slow pace to be able to keep track of individual elements and see interactions would require hours to explore the entire process.
%On the other hand, observing the simulation in fast-forward would shorten the viewing length but it would become impossible to observe important reaction events because of the fast pace at which elements would be moving.
%
%While solving ordinary differential equation systems of kinetic models is very straightforward, agent-based models must represent and simulate every single reacting entities, and that are usually present in large quantities.
%The simulation of particle-based systems is thus very demanding in terms of computation and is usually precomputed prior the visualization.
%This limitation thus prohibits online interaction with the simulation parameters and real-time exploration of multiple simulation scenario.
%Even most-optimized simulation tools that leverage the power of GPU computing [][], specifically developed for \textit{in-situ} visualization are still not able to deliver a true real-time user experience.
%Quantitative modeling methods do not feature 3D dimensional data but are also much faster to compute, and could easily be simulated along with a complex 3D visualization.
%Therefore it would also be interesting to explore the use of real-time quantitative information to animated 3D particle based on real simulation data but at a much lower cost than agent-based methods.


% far it has not been proven how this method would perform with other types of molecular ensembles present in living cells such as DNA fibers or lipid membranes.
%This method also requires additional supporting grid structures containing atomic data for the ray-casting rather than just the ray data.

%Our approach follow-up the work of Lindow et al. who rely in the GPU pipeline.
%We also inspired from Grottel et al. for the occlusion culling.
%We aslo inspired from the continuous level-of-detail approach from Parulek et al.
%We wished to stay away from ray-casting supporting structures for various reasons:
%
%Harder to setup, than simply using the raw data.
%Limitation of ray-casting, for complicated for optimization.
%Potentially larger video memory occupancy than raw data.
%No efficient support of fibers and lipid membrane structures.
%
%The method based on sphere impostors do not have these limitations.
%But they are also much slower.
%How to improve them ?

\section{Rendering and Composition of Molecular Landscapes}

Up to this point, the rendering methods presented in the visualization literature have reached unprecedented levels of performance, in terms of size of supported datasets and rendering speed, thus enabling real-time rendering of large molecular structures generated with cellPACK[].
The most recent presented solution is capable of rendering 25 billion atoms at 3.6 fps in HD resolution.
However, the rendering approach fails to provide a comfortable user experience as one expects between 24 and 60 Hz on average for interactive entertainment, and at least 60 Hz for dome and VR content.
The rendering should also free enough resources for eventual additional computation, as for instance, the physics simulation of the molecular bodies for real-time animation.
Moreover, none of the techniques mentioned above have proved to efficiently support other types of molecular structures that exhibit much more complex organization, such as lipid membranes, nucleic acids or fibers, which ought to be taken into account for a truer depiction of molecular landscapes.
These are indeed more challenging to render, because the assembling blocks of these structures are considerably smaller and also more numerous than with protein data.
In order to provide a truer depiction of micro-organisms and improve real-time user experience, we decided to investigate new rendering approaches that would address all these limitations.
We opted for an impostor-based method for the design of our rendering pipeline, which directly follows-up the work of De Lampe et al.[].
An advantage of sphere impostors is that they do not require additional supporting structures for the rendering and are also more trivial to render than molecular surfaces, while providing high quality surface details.
The optimizations which we developed are inspired from well-known computer graphics techniques often used in games such as level-of-detail, instancing and occlusion culling, which have been adapted to support macromolecular datasets efficiently.

A particularity of the scenes generated with cellPACK is that they aim at reproducing molecular crowding which can be observed in vitro.
So far, the rendering methods previously presented have only showcased protein datasets with a very low population density, which means that less macromolecules are present in the viewport at once.
Additionally to increasing the rendering complexity, denser scenes may also cause major occlusion issues for viewing important internal structures such as the DNA for example.
Hence, we designed an custom scene composition pipeline to adjust the visibility of proteins, while preserving important contextual information.
The pipeline is also engineered to leverage the power of GPU, and provide a responsive user experience even with a large number of individual molecular agents.


\textbf{Level-of-detail}

Level-of-detail (LOD) is a method often used in computer games to cope with the limited polygon budget of real-time applications.
The principle consists of drawing simpler mesh representations for distant objects that have less pixel coverage to reveal high-frequency details. 
From an original 3D model with a high number of polygons, proxy models are generated to create an atlas of model with gradually simplified geometries.
Upon rendering of a model, the LOD proxy is then selected based on the distance to the camera.
The further away an object lies, the less details can actually be observed and thus less polygons should be rendered.
This concept was applied to molecular visualization by Parulek et al.[] who presented a continuous level-of-detail for molecular surface rendering.
Molecular surfaces such as SES[] are often used for scientific exploration of cavities and pockets.
Because computing SES for dynamic data in real-time is expensive, they propose to restrict the computation to a smaller subset of the surface in the focus region.
They seamlessly transition from SES to Gaussian surfaces for the context region.
Gaussian surfaces are more trivial to compute but also provides less high frequency details.
To push the rendering capabilities even further, they also simplify the atomic structure of the proteins for the most distant context region.
They use clustering algorithms to simplify the atomic structure of a protein with fewer and larger spheres, as seen in Figure X.
Since the structure comprise less spheres to contribute to the surface, the computation of the distance field is much less expensive, but still preserves low-frequency shape details.
We also use clustering to simplify protein structures, but we render the larger spheres, or meta-atoms, resulting from the clustering, as 2D impostors instead of compute a surface.
Clustering allows a reduction of the number of spheres from 75pc for the first LOD proxy up to 99pc for the most simplified proxies.
We also use different shading materials for original atomic structures and the proxies.
For proteins closer to the camera and showing the entire atomic data, we highlight the surface details using high-frequency illumination.
For proteins located further away that are showing only simplified structures, we only highlight low frequency details to make the meta-atoms less salient and the overall shape smoother.
Although simplified protein structures are much faster to render than original structures, when dealing with a large number of proteins it is also important to limit the number of draw commands in order to reduce GPU-driver overhead.
Therefore, we also developed an optimized rendering pipeline which is able to render an entire set of proteins in a single draw command.
Compared to traditional instancing methods, the pipeline is able to switch between different LOD proxies on-the-fly during the GPU rasterization process.
%The pipeline is designed to switch between proxies levels on-the-fly, and to draw the scene in a single draw command.

\textbf{Instancing}

Instanced drawing is a concept widely used in computer graphics that aims at reducing the memory bandwidth and usage as well as reducing the GPU-driver latency cause by a large number of draw commands.
This concept was applied by De Lampe et al.[] who used the geometry shader stage to instantiate the atomic structure of entire amino acids, also called residues, directly from the GPU rasterization pipeline.
Amino-acids are the building blocks of proteins, and there is around 20 different types of amino-acid.
They initially store the atomic structures of each residue types in the video memory in a dedicated buffer, as well as the position, rotation and type, of each amino acids that compose a protein, in separate buffer.
With their method, they are able to render an entire residue with a single initial per-vertex operation.
During the vertex shader execution, amino-acid properties such as position, rotation, and type, are read from the video memory and passed on to the next shader stage, i.e., the geometry shader.
The geometry shader program then fetches the local atom positions for the corresponding residue from the video memory, which are then transformed with the residue position and rotation.
For each residue atom, new triangles are injected around atom centroids, and then processed in the final per-pixel shader stage to form 2D sphere impostors, similarly to Tarini et al.[].
It is also possible to launch the execution of multiple vertex shader programs in a single draw operation, thus reducing the latency accumulation caused when sending rendering commands to the GPU multiple times.
Given a protein composed of 4000 atoms and 250 amino acids, the memory footprint of a protein would thus be reduced from 16000 numbers (4000 * 3D positions and atom type) to 2000 numbers (250 * 3D positions + atom type + 3D rotations).
Although there is a finite number of amino-acid structures, it also exists an infinite number of possible rotational conformations, which means that it is challenging to accurately depict protein structures with this approach.
To address this limitation, it would be ideal to apply the same concept to entire proteins instead of residues.
Such approach would also help to considerably reduce the memory footprint of the scene as only the type, position, and rotation would suffice to describe a single protein.
However, the geometry shader causes a considerable latency as the number of injected geometries increases, and therefore it is only possible to instantiate a few dozens of triangle efficiently with this method.
Indeed, a single geometry shader program is responsible of transforming and injecting multiple geometries, but this operation is completely performed in serial while it would be more efficient to distribute the workload across multiple threads instead.

The tessellation shader is a feature that is now available on most recent graphics hardware, and is also available on mobile devices.
Similarly to the geometry shader, this shader stage is designed to dynamically inject primitives on-the-fly in the rendering pipeline.
While the geometry shader is only design to inject a few dozens of triangle maximum, the tessellation shader is able to efficiently inject thousands of vertices by dispatching the work on multiple threads.
Initially, the feature was developed to selectively increase the level-of-detail of meshes based on the camera distance and surface curvature.
The tessellation engine is also able to inject other types of primitives than polygons, such as lines or vertices.
We use this feature to dynamically control the number of atoms or meta-atoms that shall be drawn, directly in the rendering pipeline.
Similarly to De Lampe et al.[], only one initial vertex shader thread is required to draw an entire molecule, but the maximum size of molecules which is supported is up to two orders of magnitude greater with our approach.
The vertex shader, which is the first stage of the pipeline, is used to fetch protein information such as position, rotation, and type, from the video memory, and these will then be passed on to the next stages of the pipeline.
Based on the protein type and distance to the camera, we select the corresponding LOD proxy, which informs us about the number of spheres required to draw the given protein.
We then notify the tessellation engine about the number of vertices that we want to inject, i.e., one vertex per atom or meta-atom.
The tessellation engine will then dispatch the execution of a thread batch comprising one thread per vertex.
Each thread is initially given a unique ID, which is then used to fetch the corresponding sphere information from the main video memory, such as the local position and radius of atoms or meta-atoms.
After transforming the local sphere position with the protein position and rotation, the sphere centroid is passed on to the next shader stage, i.e., the geometry shader.
Subsequently, the geometry shader is used to inject the remaining vertices around the sphere centroids, to form the triangles of the 2D sphere billboards.
An advantage of this technique is that it allows to render an entire scene comprised of several hundreds of thousands of proteins in a single draw command, thus approaching zero driver overhead.
Additionally the memory footprint is considerably smaller than previous techniques, and the pipeline is also able to process large macromolecules with up to several thousands of atoms.

\textbf{Occlusion Culling}

%is the rendering stage which the most demanding and causes a bottleneck in the pipeline.
%Mesoscale datasets such as the one generated with cellPACK often result in a very dense arrangement of macro-molecules.

Upon rendering complex scenes, a large number of geometries are processed through the rendering pipeline, which may overload the graphics hardware and cause bottlenecks.
Per-fragment processing is by far the most demanding stage of our pipeline.
Because the scenes are very dense, a large number of spheres overlap each other at a single pixel location,
which in turns results in a overly large number of concurrent tests and slow down the rendering.
An efficient way to reduce this computational load is occlusion culling, and is also widely used in computer games.
The principle of occlusion culling is to exclude objects that are partially or completely hidden by other visible objects from the rendering pipeline, in order to spare computation.
It exists on modern graphics hardware a fixed functionality called hardware occlusion queries (HOQ), and which allows to compute the number of visible pixels of rasterized geometry based on an input depth texture.
The depth texture may either be generated before hand (depth-only pre-pass), or simply recycled from the previous frame.
Grottel et al.[] presented an efficient rendering pipeline for large particles-based datasets, using HOQ to discard large chucks of the dataset hidden in the current viewport.
They use a uniform grid to spatially partition the dataset, and perform occlusion queries for each grid cells, using cubes as bounding geometries.
Each query result is individually read back to the application after a certain latency which is due to the processing in the graphics pipeline.
Additionally, since one draw command must be issued for each single query, the GPU driver overhead causes a small latency that accumulates with the number of queries.
For the specific use-case demonstrated by Grottel et al.[], this approach seems reasonable because of the relatively low number of queries needed (one query per grid cell with a 15x15x15 resolution).
In our use-case, we would need to perform one occlusion query for each individual macromolecule present in the scene.
Averagely complex scenes generated with cellPACK may easily comprise up to millions of individual instances when small lipid molecules are present, and therefore the presented approach is guaranteed to perform poorly with such scenes.

A more suitable approach would have to be specifically designed to reduce execution times of individual queries and also to limit GPU-driver overhead.
Hierarchical Z Buffer (HiZ buffer) is a method introduced by Green et al[] and is commonly used to efficiently perform visibility look-up's.
Based on an input depth map, they compute mip-maps with a custom algorithm in order to only retain the deepest values for each texture down-sampling operation.
Hence, a single pixel from a lower resolution mip-map will indicate the deepest value from the entire region covered by this pixel in higher resolution mip-maps.
Subsequently, for each object to be queried, they compute a camera-facing bounding square.
Based on the pixel coverage and position of the squares, they perform a series of look-up at a specific resolution in order to minimize the number of texture accesses, that tend to slow the computation.
The use of camera-facing squares as bounding regions allows to cover the entire square with only 4 texture look-ups at the right mip resolution, thus guaranteeing a constant execution query time regardless of object sizes.
Finally, in case the depth of a given square is deeper than all of the four values queried, the object is then guaranteed to be hidden and may safely be discarded from the rendering pipeline.
A disadvantage of this method is that it may indicate objects as visible while actually being occluded, because it reduces large regions of an initial depth buffer to a few depth values.
In our use case, however, we must trade-off accuracy against performance, because more accurate occlusion culling approaches are simply too computationally demanding to cope with the size of our datasets.
However, without a proper query batching mechanism, the GPU-driver overhead caused by individual draw-commands would simply be too high to allow real-time rendering performance.
We propose to adapt this method to run in parallel on graphics processing units in order to perform multiple queries simultaneously, and thus speeding-up the operation.
Because only one thread execution is needed to compute a single query, we are also able to dispatch the GPU computation of multiple queries in a single command, thus approaching zero GPU overhead.
With our most complex scene, we were able to spare up to 50pc of the rendering computation thanks to our batched occlusion queries.
 
\textbf{Fibres Structures}

%It is also worth mentioning that the proposed modelling approach does not aspire to provide a strictly accurate depiction of DNA structure.
%Instead, we aim a showcasing an resembling representation of the structure which is fast to compute and designed for illustration purposes only.

An utterly important component of living organisms are fibre structures such as DNA, RNA or (...).
Similarly to protein data, a challenge when rendering dynamic fibre structures is memory usage and bandwidth.
Fibres such as DNA, are composed of small molecules called nucleic acids, also known as bases, and which are made out of a few dozen atoms.
One approach to render fibre structures would be to store the position, rotation, and type, of each nucleic acids and to render the bases with the same pipeline used for protein data and described above.
However, we foresee two issues with that approach.
Firstly, the memory footprint of DNA strands might simply be too large to store the genome data of entire cells on the video memory.
Indeed, the entire genome of E.Coli, for instance, is composed of xxx individual base pairs, which represents xxx Gb of data.
Secondly, simulation tools that are able to reproduce the dynamics of DNA fiber structures are all CPU-based algorithms.
Assuming that storing large static structures is already a challenging enterprise, the rendering of animated structures would very likely have to be streamed to the GPU instead.
Interactive rendering of animated DNA structures would therefore be limited with this approach, because the cost of memory transfer between CPU and GPU would slow down the rendering considerably.

Our solution to limit the memory footprint of fibre structures is to only use the control points of the fibre strands as input, while generating the actual fibre structures on-the-fly.
The rendering pipeline which we developed for the fibers relies on the tessellation shader to dynamically inject spheres impostors that compose each fibre segments, similarly to protein data.
An advantage of our fibre rendering pipeline is that previous technologies developed to optimize the rendering of protein data, such as LOD or occlusion culling may also be seamlessly used with the fibre use-case.
Additionally, since only the curve data is needed as input, the animation of the fiber structures becomes much more trivial to compute.
Indeed, mainstream physics animation tools that are GPU-based may be used instead of CPU-based scientific tools, which guarantees a considerable performance boost.
In order to support different types of fibres, it is important to first understand how their structures is organized.
In the case of DNA fibres, a well-known structure is the B-DNA, that exhibits the recognizable double-helix pattern.
The structure is also very simple to model: a spacing of 3.4Å and a rotation of 34.3 degrees between each nucleic acids. 
We also define an average number of 12 nucleic acids per segments.
Based on these knowledge, we are now able to generate B-DNA curve segments simply based on a set of curve control points.

The pipeline is designed to render an entire curve segment from only one initial per-vertex program.
As an input, the vertex program reads the controls points information for the current segment as well as the building rule of the current fibre structure.
The building rules and the segment curvature are used to compute the position and rotation of the nucleic acids along the curve segment, and this information is then passed on to the next shader stages.
Based on the building rules of the segment and its distance to the camera, we estimate the number of spheres which are required to draw the fibre segment.
We then notify the tessellation engine about the number of vertices that we want to inject, i.e., one vertex per sphere.
The tessellation engine will dispatch the execution of a thread batch comprising one thread per sphere.
Upon processing individual spheres in the tessellation stage, the corresponding sphere information is fetched from the main video memory, such as the local position and radius of atoms or meta-atoms.
After transforming the local sphere position with the position and rotation of the nucleic acid that it belongs to, the sphere centroid is passed on to the next shader stage, i.e., the geometry shader.
Subsequently, the geometry shader is used to inject the remaining vertices around the sphere centroids, in order to form the triangles of the 2D sphere billboards.

\textbf{Occlusion Management}

The phenomenon of molecular crowding is used to describe as solution when high concentrations of macromolecules such as proteins are present.
Such conditions occur routinely in living cells; for instance, the cytosol of Escherichia coli contains about 300–400 mg/mL of macromolecules.
Therefore an accurate depiction of living organisms often result in a very dense arrangement of macromolecules as shown in Figure X[].
Without efficient means to selectively remove occluding objects, it would therefore be impossible to observe hidden internal structures that play essential roles in the functioning of biological systems.
In scientific illustrations and visualization, cutaway views are often employed as an effective technique for occlusion management in densely packed scenes.
However, a limitation of strict cutaway views is that important contextual information is removed.
Illustrators must make sure that the essential information, e.g., the ratio of multiple molecular ingredients is represented, and not simply clipped away.
While mainstream visualization and illustration software feature cutaway tools, they do not provide the means to easily perform advanced scene composition for such scenes.
Transparency is another approach to solve occlusion problems, although the computational cost of full-fledge transparency will be too significant for large molecular scenes featuring several thousands of overlapping elements.
Furthermore, due to the presence of a large number of potential occluders the use of transparency will likely result in overly complex images which would affect the quality of the visualization.

We propose a novel method for solving occlusion problems due to molecular crowding.
In contrast with existing techniques, we take advantage of the characteristics of complex molecular landscapes such as the scenes modeled with cellPACK.
These models usually comprise hundreds of thousands of individual macromolecules, however many of them share the same structure.
Therefore, by reducing the concentration of elements sharing a similar structure, we may reveal hidden structures and also preserve important information such as the structure of contextual elements and their location.
This concept resembles the “Screen-Door Transparency” technique popular in the early days of computer graphics and where transparency is achieved by placing small holes in a polygon to reveal what is present behind.
When reducing the concentration we also ensure that elements are removed uniformly across the scene to preserve the initial proportions of the spatial distribution.
A potential limitation of this approach is that it will communicate erroneous information about the concentration to the viewer.
In order to avoid misconceptions, we optionally propose to display the removed elements with a ghosting effect such as transparency or contours only.
The main difference between the ghosting effect and full fledge transparency is that only the last occluding elements are blended on top of the opaque and visible elements to minimise visual clutter.

To assist the scene composition, we additionally display a bar chart over the view that provide real-time quantitative feedback about the visibility of each macromolecular type.
A single bar comprise three distinct regions that indicates the visibility properties for a given species as show in Figure[].
The grey region bar indicates the number of macromolecules that are currently discarded from the rendering.
The dark green region indicates the proportion of rendered molecules that are currently visible, while the light green region indicates the proportion of them that are currently occluded by other macromolecules.
The bar chart thus provides an overview of the visibility properties which then serve as guidance for composing the scene.
For instance, if the user wishes to observe a particular species, he will immediately be informed about the quantity of this species that are occluded by other structures, and will adapt the visualization accordingly.
The modulation of the proportion of visible elements is also done via the quantitative view by simply dragging the border between the grey and green regions. 
Another useful functionality for scene composition is the selection of species of interest.
When selecting a particular macro-molecular type as species of interest, occluding elements of a different types are then guaranteed to be discarded in order to provide full-visibility for the species of interest.
Since this method is view dependent it is necessary to compute occluding elements routinely when the camera position is updated.
Therefore, we developed a custom culling pipeline using GPU computing to guaranty a smooth user experience even with scenes featuring a large number of macro-molecules.
Macro-molecules that are set as species of interest are first rendered in a separate off-line depth texture and used as input to perform image-based occlusion queries for each of the remaining elements and detect occluders.
Additionally to our quantitative approach for occlusion management we also provide support for traditional clipping objects such as planes, cube or sphere that can manually be placed in the 3D scene.

% imitating the reaction and diffusion process for 
%
%
%spatial behaviour of the molecular diffusion and reaction in three dimensions in order to study the 
%
%
%The principle
%
%It also exists 
%
%
%
%
%In order to be able to compute 
%
%
%such simulation in a reasonable amount of time, the behaviours of the macromoelcules is simplified.
%
%
%Similarly to MD or BD ind
%
%In particle-based modeling each molecular agent is represented as a 3D no matter its size.
%
%[Show diagram]
%
%results are very cluttered.
%
%Although previous works attempted to improve the raw visualization of particle-based visualization, there is still left to address the several major grand challenges.
%
%Visual guidance, temporal close-ups, bladibla.
%Interactivity.
%
%
%%However, these simulation methods are still too complex to reproduce complete biological systems for entire cells because these systems are simply too large and would require too many simulation steps.
%
%
%
%
% because it would simply require too many simulation time steps and elements you be too
%
%
% computationally demanding to reproduce and entire processes 
%complex 
%
%
%initialize s
%
%
%as input for dynamic simulation tools that require as input an initial macromolecular arrangement without
%
%
%The models were initialy developed to serve as input for dynamic simulations tools such as molecular dynamics or brownian dynamics that require an initial structure which is valid, i.e., a logical arrangement of proteins without overlapping structures.
%
%Limitation of brownian dynamics, local phsical atomic interaction, complex to compute large systems and small time steps must be used.
%
%
%Computational biology also comprise simulation tools that are able to simulate an coarse approximation of molecular trajectories as well model individual reactions for an entire biologocal system.
%
%Allows to model larger and longer simulation, because it greatly simplifies molecular interaction compared to BD, MD.
%
%In particle-based modeling each molecular agent is represented as a 3D no matter its size.
%
%[Show diagram]
%
%results are very cluttered.
%
%Although previous works attempted to improve the raw visualization of particle-based visualization, there is still left to address the several major grand challenges.
%
%Visual guidance, temporal close-ups, bladibla.
%Interactivity.
%



% would be a challenging enterprise because the modeling setup is not streamlined, and each snapshot would require cumbersom manuall steups.
%
%
%this technology 
%
%
%produces unique m
%
%
%does not provide any sort of correspondence between two models, and the
%
% is not able to produce local transition between two states since there is no correspondence between models.
%
%
%
% of from state to another there is no correspondence between two models that would allow to generate transition between two snapshots.  
%
%
%modeling approach is not yet designed for the creation of animated datasets.
%
%Although it is possible to create a multitude of models to transition of from state to another there is no correspondence between two models that would allow to generate transition between two snapshots.
%
%
%
%
%a mature and immature re [show images].
%
%
%One 
%
%
%Although it is possible to model 
%
%
%Scientists at the Scripps Institute of San Diego have already produced two different states of the HIV virus, mature and immature [show images].
%
%
%
%
% models only represent statically microscopic organism and do not feature any information about the future states.
%
%
%
%
%
%
%%
%% important details such as the shape
%%structural information visible at multiple scales 
%%
%%
%%
%%Upon the rendering of these models it may be challenging to display 
%%
%%The rendering of these models 
%%
%%These models can represent a challenge for real-time rendering but optimization inspired from computer games may we developed and adapted to speed up the rendering and advanced composition of commodity hardware.
%%
%%However, these models only represent statically microscopic organism and do not feature any information about the future states.
%%
%%The HIV virus for instance, undergoes multiple transformation during his life cycle, and showcasing only one single state would fail at revealing the functioning of the virus.
%%
%%Scientists at the Scripps Institute of San Diego have already produced two different states of the HIV virus, mature and immature [show images].
%
%%However, this modeling approach is not yet designed for the creation of animated datasets.
%%
%%Although it is possible to create a multitude of models to transition of from state to another there is no correspondence between two models that would allow to generate transition between two snapshots.
%%
%%Additionally to produce a large number of models would be a challenging enterprise because the modeling setup is not streamlined, and each snapshot would require cumbersom manuall steups.
%
%
%The models were initialy developed to serve as input for dynamic simulations tools such as molecular dynamics or brownian dynamics that require an initial structure which is valid, i.e., a logical arrangement of proteins without overlapping structures.
%
%Limitation of brownian dynamics, local phsical atomic interaction, complex to compute large systems and small time steps must be used.
%
%
%Computational biology also comprise simulation tools that are able to simulate an coarse approximation of molecular trajectories as well model individual reactions for an entire biologocal system.
%
%Allows to model larger and longer simulation, because it greatly simplifies molecular interaction compared to BD, MD.
%
%In particle-based modeling each molecular agent is represented as a 3D no matter its size.
%
%[Show diagram]
%
%results are very cluttered.
%
%Although previous works attempted to improve the raw visualization of particle-based visualization, there is still left to address the several major grand challenges.
%
%Visual guidance, temporal close-ups, bladibla.
%Interactivity.

\section{Emulating the Machinery of Life}

Biologists from the Scripps Institute have pioneered the ambitious enterprise of capturing the atomic structure of entire viruses or cells.
These models are valuable for scientific and educational exploration because they contain structural information that can be observed at multiple scales, such as compartments shapes, spatial arrangement of macromolecules, and atomic structure of each macro-molecule.
Rendering such scenes interactively without compromising on the amount of displayed information is challenging.
To speed up the scene rendering and composition on commodity hardware, we adapted several concepts from computer games such as instancing, and level-of-detail.
However, the representations of these microscopic organisms are static and do not provide any information about the future states or important biochemical processes that are ongoing internally.
The HIV virus, for instance, goes through multiple transformations during his life cycle [show figure], and showcasing only one single state would not suffice to revealing its functioning.
Scientists have attempted to produced several states of the HIV virus life cycle, which now comprise representation of the virus in its mature and immature state[show figure].
However, with this technology, the modeling process is stochastic and does not provide logical correspondence between the models, which simply forbids key-frame animation between two states at this stage.
Additionally, producing enough models to generate an animation would be challenging and also time consuming because the modeling process is not streamlined and require complex manual setup for each model.

In structural biology, dynamics simulations, such as molecular dynamics (MD), or brownian dynamics (BD) are used to reproduce the physical behaviour of groups of atoms in three dimensions, in order to understand their function.
The initial purpose of cellPACK was to generate models that could serve as initial state in order to run large scale dynamics simulations on super computers.
In computational biology, it exists a gap between structural and systems biology caused by the limitation of today's computers.
Indeed, MD and BD simulations are simply too computationally expensive to reproduce the dynamics of biological systems for entire cells, and are restricted to smaller use cases in terms of size and duration.
Systems biologists, on the other hand, are interested in studying in the dynamics of entire biological systems, but they also value quantitative information more than spatial information.
Therefore, they often employ strictly quantitative modeling approaches, which are computationally inexpensive.
More recently, spatial particle-based methods for modeling reaction networks have emerged.
Their principle consists or reproducing the behaviour or spatial diffusion and reaction for a large number of molecules in order to study the changes in species quantities over time.
In order to reduce computational costs, the reaction diffusion processes is extremely simplified.
Particles are subject to random walk to simulate molecular crowding without having to take into account surrounding macromolecules that do not play a role in the simulated process.
Individual reactions are triggered upon collision events between two potential reaction partners.
Particle-based modeling is thus a very singular approach as it provides spatial information for individual proteins and allows computing complex reaction networks in a reasonable amount of time for entire cells.
In this section, we will investigate the use of particle-based systems to showcase the dynamics of processes in three dimension in order to complement the large but static scenes modeled with cellPACK. 

\subsection{Observing Multiple Time Scales at Once}

Particle-based modeling, also known as agent-based modeling, reproduces entire biological systems to explore their dynamic properties.
Particles are individually modeled and interactions between them are virtually taking place in the 3D space.
Additionally to quantitative information which is valuable for understanding the functioning of a system, the modeling approach is also capable of producing 3D trajectory data and reaction log as output, which can be used to visualization of spatial data.
Falk et al.[] designed a visualisation tool to playback the particle trajectories resulting from the simulation in 3D space.
A major challenge with this type of visualization is visual clutter due to the large number of particles diffusing in every direction.
In order to visualize individual reactions it is therefore necessary to close-up on participating particles and also to reduce the playback speed in order to keep track of individual reactions.
Because particle simulations operate at very small time steps, typically of the order of nanoseconds, the resulting number of steps can often be very large. 
At the reduced pace required to see individual reactions, the viewing of the entire simulation frames may lead to overly long visualization sequences.
To shorten the duration of the visualization, it is common to only display simulation frames spaced at a constant given interval. 
This is usually referred to as fast-forward or timelapse.
The time-scale discrepancy between process and reaction thus complicate the visualization task as the viewer must manually switch from fast forward to normal speed in order to observe the multiple scales of a phenomenon.
To address this issue, we propose a new type of visualization that enables the viewing of individual reactions while playing back the simulation in fast forward.
We believe that effective fast-forward visualization can be achieved by respecting a few guidelines which we enumerate as follows:

%\textbf{R1:} The visualization should show the simulated process in a reasonable amount of time, irrespective of the number of simulation frames.
\textbf{R1:} Individual particles should move slow enough to be traceable with human eyes, especially those with a high degree of interest.
\textbf{R2:} Events of interested, such as reactions should be salient and last enough time in order to be seen by a human eye.
\textbf{R3:} Despite eventual alterations to respect the previous guidelines, the visualization should be as realistic as possible to avoid misconceptions. This requirement is in accordance with the results of a study by Jenkinson et al. [14], which demonstrated that a more realistic depiction of a process can enhance the viewer’s understanding compared to a highly abstracted one.

\textbf{Speed Reduction}

To reduce the viewing length of a simulation, we only display trajectory snapshots spaced at a given time interval, while preserving a fast pace between two displayed snapshots.
Fast forward visualization thus results in more visual clutter, as the position information between consecutive frames is omitted which results in large particle leaps.
In some configurations, with a large number of particles, it might be difficult to keep track of single particles between too consecutive frames.
To satisfy \textbf{R1} we apply a speed reduction filter to shorten the trajectories of individual particles.
The filter consists of reducing displacements between the current position of particles and their original trajectory positions sampled from the dataset at a given time.
The displacements are reduced according to the speed reduction factor as shown in Figure[x].
Particles thus follow their original trajectories but are displaced over shorter distanced which also decreases their speed.
This produces a small delay between particles and their original trajectories, however, because the magnitude of each displacement is proportional to the distance of a particle and its original trajectory, this delay does not accumulate and remain constant over time.
As a result, particles always remain in the vicinity of their original trajectories and their motion is smoother and easier to follow by human eyes.

\textbf{Reaction Highlighting}

In particle-based simulation of biochemical reactions networks, reactions are punctual events that occur upon collision of two potential reaction partners.
In the event of a reaction, the resulting products will immediately be injected in the system as the operation is performed in a single simulation step.
Therefore, it might be difficult to observe single reactions.
Additionally, when viewing the simulation in fast-forward, many important reaction events might simply be omitted due to frame dropping.
Without showing reaction events, molecular agents will appear and disappear from the visualization without providing the necessary visual clues to understand what might have caused it.
We therefore prolong the duration of the reactions to make them stand out and to inform the viewer about the nature these events.
Shortly before each reaction event, we apply attraction forces to steer the reactants towards the reaction location. 
During this procedure the original motion of the particle is overwritten by attraction forces.
To emphasize reaction events, reacting elements are highlighted with vivid colors to contrast with the rest of the scene.
The slow attraction animation and the color highlighting thus guarantees that the viewer is informed that a reaction is about to happen.
Once a reaction is accomplished, the products are introduced and their original motion is restored.

\textbf{Lens Effect}

Because of the slow movement of the particles compared to their original trajectories, the viewer may be misguided about the true diffusion properties of molecular agents.
To preserve a realistic impression of molecular motion despite trajectory reducing, we introduce a temporal focus+context technique that applies visual abstraction of molecular trajectories solely in the foreground (focus), while showing more realistic -yet often untraceable- motion in the background (context).
By showing the actual particle trajectories in the background we want to create an illusion of chaos, thus informing the viewer about real diffusion speed while allowing him to observe important reaction events in the same view.
We propose two methods to achieve this effect.
The first method operates in object space.
We define a region anchored in front of the camera in which molecular agents will be subject to a higher speed reduction.
Outside of this region we progressively decrease the speed reduction until reaching the background zone where the original particle trajectories are shown.
The second method we propose operates in image space.
We limit the displacement of particles to a distance defined in pixel-space and based on the smooth pursuit eye movement limit used in psychology research.
When using a perspective projection in the visualization, elements close to the camera appear to move much slower than those further away in z direction. 
In fact, their screen space velocity is approximately the same, This illusion is due to the differences in pixel coverage of particles that are located in the background.
This effect results in a smooth and continuous transition between the motion of front and background particles, which is more tedious to obtain with the world-space approach because it requires additional fine tuning.

\subsection{Quantity-Driven Particle Animations}

In systems biology, it exists various modeling approaches that are either deterministic, such as quantitative modeling, or stochastic, such as particle-based modeling.
One advantage of the agent-based approach for the visualization, is the presence of spatial information which can easily be displayed in a 3D view.
Although the output is usually very cluttered, it is possible to apply filtering methods to improve the visualization as shown in Section[].
However, the computation of particle-based models is much more demanding compared to quantitative modeling, because it must accounts for the reaction and diffusion of each single reacting entities, which are usually present in large quantities.
The simulation is therefore often precomputed prior the visualization.
As simulations are complex to setup and to compute, the creation and exploration of multiple scenario is thus slowed by this workflow.
Additionally, with large and complex model the resulting trajectory files may be very large, over xx GB for XX frame and XX individual particles, which is impractical to manipulate when dealing with a multitude of different scenario.

Our grand vision is to digitally reproduce the dynamics of the machinery of life, and therefore we are mostly interested in mapping spatial and quantitative information to structural information in three dimensional space, rather than producing a large amount of data and run complex post-processing analysis.
Therefore, more efficient workflow for this use case would be to visualize the particle positions on-the-fly as the simulation advances.
With such approach, it would be possible to influence the course of a simulation, for instance, increase the temperature, or introduce new species, and to directly observe the impact of these changes without having to run another simulation or deal with overly large files.
Most-efficient simulation tools, such as Smoldyn[], are able to compute single simulation steps in a matter of seconds, thanks to efficient parallel algorithms running on GPU.
A few tools additionally support \textit{in-situ} visualization of particle-based models computed in real-time with such approach.
However, the computation is still too demanding to deliver a smooth user experience even on high-end commodity hardware, which prohibits the use of online simulation for interactive and explanatory applications.

Additionally, to visualize and understand a biological system, one must be able to observe the logical cascade of reactions described in the reaction network, as depicted in scientific animations.
With particle-based modeling, it is impossible to influence where and when reactions will occur.
Therefore, the viewing of an entire cascade of reactions may be very tedious because it requires manual spatial exploration and waiting times between successive reactions.
To overcome this issue, we would have to gain control over where reactions might occur.
This can only be achieved by decoupling the quantitative information from the spatial information.
In other words, we would need to use a modeling approach that would allow us to overwrite spatial information without influencing the course of the simulation.
Quantitative modeling methods, such as kinetic modeling, do not feature particle trajectory data.
They are also much faster to compute and could easily be simulated along with a complex 3D visualization with high frequency refresh rates.
To address the previous limitations of particle-based modeling, we thus chose to explore the use of quantitative information to drive 3D particle animations in real-time.

With particle-based modeling, the behaviour of individual particles directly influences the concentration of species overtime, as reactions are only triggered by collision events
Given a reaction \textbf{A + B -> C}, for example, when two reactants A and B are closely located from each other, then a reaction is likely to occur.
In the event of a reaction, elements A and B will then fuse to produce element C, thus increasing the concentration of element C and decreasing the concentration of elements A and B.
In particle-based simulations, individual agents are thus actors of their own fates.
We propose a new type of particle system where the behaviour of particles is purely driven by quantitative information.
We introduce a new type of agent, whose behaviour mostly depends on external parameters, and which we dub passive agents.
As the quantitative simulation advances, the system will query the number of reaction to occur at a given time, and subsequently force passive agents to react.
Hence, passive agents do not play any role in the simulation process, their only function is to act as a visualization proxy to show quantitative information in three dimensions.
While the visual output is hardly distinguishable from an actual particle-based simulation, the benefits of this approach is two fold.
Firstly, the simulation of the reaction network is very lightweight to compute, which makes this approach much more usable for interactive applications.
Secondly, the spatial information is completely decoupled from the simulation, which means that we can have control over where reactions will occur.
This approach grants us the freedom to dynamically trigger a cascade of reactions directly in the viewport in order to facilitate storytelling of complex reaction networks.

The workflow of our passive-agents system is laid out as follows [Figure needed]:
On the one hand, we have a biological system described as a reaction network and modeled with a scientific simulation software using a kinetic modeling approach.
On the other hand, we have a 3D scene filled with potential reactants, and which is setup according to the initial conditions of the model, such as the initial quantity and location of each species.
Each passive-agent additionally undergoes a 3D random walk motion to simulate the diffusion process, similarly to traditional particle-based simulation.
We then routinely query the quantitative simulation to fetch information about the number of reactions that are meant to occur at time t.
Assuming a reaction of type \textbf{A + B -> C}, for example, the particle system will first randomly select two elements A and B based on their spatial proximity.
The two particles will then be subject to attraction forces until they enter in collision.
Upon collision of the reactants, the reaction is performed, products are injected and the reactant are removed from the system.
Finally, the reaction products return to a normal diffusion behaviour until they get chosen for a subsequent reaction defined in the network.
By default, the reaction participants are randomly chosen in the 3D scene, but it is also possible to set a reaction priority to a few elements present in the viewport, in order to show cascades of reactions without having to browse through the entire scene.

\section{Conclusion and Future Work}


%We will then exert and an attraction force to these two elements in order for 
%
%
%The two elements will them exert 
%
%For the duration of the reaction the tw
%
%
%
%
%
% at a given time t we extract from the quantitative simulation how many reactions of type  are meant to occur.
%
%
%
%To explain the concept of the passive agents in more details:
%let us first assume a given raection network which is computed with a quantitative simulation tool.
%And let us also assume a 3D scene filled with potential reactants, and which is setup according to the initial conditions of the model such as the quantities of each species, and the compartment.
%Each single agent is diffusing freely, similarly to traditional particle-based simulation.
%Then at a given time t we extract from the quantitative simulation how many reactions of type A + B -> C are meant to occur.
%Given this information elements A and B are randomly chosen based on their spatial proximity and the two reactants are forced to meat at a given point to produce and new element C.
% is tedious as it require manual spatial exploration, and .
%Instead of lurking for reaction events we may force them to occur directly in the viewport thus 
%
%
%
%
%
%
%
% purely act a 
%
%The particles simply play the role of a view for the quantitative simulation.
%
%
%%Therefore we dub this new type of agents passive agents.
%%with our approach the behaviour of individual in purely depending on external environmental factors.
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%While
%
%
%which purely acts as a spatial view for quantitative information.
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%it will be challenging to observed individual reactions as they si
%
%
%would be very hard to anticipate individual reaction with such simulation 
%
%
% with online simulation of particle-based reaction diffusion.
%
%Playback offersmheads hup
%
%
%simulation methods are still to computationally demanding for 
%
%
%far from being usable in interactive entertainments 
%
%
%reaching the minimum requirements in terms of framerates 
%
%Finally a limitation of in-situ vsuai
%
%
%
%
%
%
%
%latency of the simulation coupled with the visualization of
%
%
%
%
%that leverage the power of GPU computing [][], 
%
%
%specifically developed for \textit{in-situ} visualization are still not able to deliver a true real-time user experience.
%
%
%
%In some case t
%
%
%As simulation a complex to setup
%
%
%This prohibits online interaction with the simulation parameters and real-time exploration of multiple simulation scenario.
%
%
%
%Productivty ? Complexity to generate datasets ? Educational perspective ?
%
%
%
%Even most-optimized simulation tools that leverage the power of GPU computing [][], specifically developed for \textit{in-situ} visualization are still not able to deliver a true real-time user experience.
%
%Quantitative modeling methods do not feature 3D dimensional data but are also much faster to compute, and could easily be simulated along with a complex 3D visualization.
%
%Therefore it would also be interesting to explore the use of real-time quantitative information to animated 3D particle based on real simulation data but at a much lower cost than agent-based methods.
%
%
%
%
%
%particle trajectory data
%
%
%
%particle-based approaches have the advantage of featuring spatial information that can easily be shown in a 3D view.
%
%
%
%Particle-based simulations have 
%
%particle-based simulations of biochemical reactions
%
%No interaction
%No control on reaction location








%, participating reactants are attracted toward the reaction location. 
%
%Before each reaction event 
%
%Information about reaction locations, times and participants is first
%read out from the simulation data in order to anticipate reaction
%events during the visualization. We use this information to associate
%new or missing particles between consecutive frames to their
%corresponding reactions, thus the birth or death of particles will
%only occur as a result of a reaction event. 
%
%Then, a few seconds before each individual reaction and until the end of the reaction, participating reactants are attracted toward the reaction location. 
%
%It is worth mentioning that during this operation particles are not longer
%subject to their original trajectories. 
%
%In order to ensure all reactants to meet each other at the right time, we apply a per-frame displacement to the particles in direction of the reaction location. 
%
%We also adapt the magnitude of these displacements according to the distance between particles and reaction sites in order to obtain uniform
%reaction durations. 
%
%To emphasize reaction events, the color of reacting elements is highlighted, thus contrasting with the rest of thescene. 
%
%Once a reaction is accomplished, the elements are subject to
%their respective original trajectories again.
%
%, it is hard to understand the addition or the disparition of particles.
%
% because they do not last longer than a simulation step or might simply be skipped due to frame dropping.
% 
%while keeping a certain distance between them.
%
% are only approaching their original trajectories without ever reaching it.
%
%%Subsequently, when displaying the next trajectory snapshot, particles will then be displaced from their current position, resulting from the previous speed reduction, toward the next position sampled from the trajectory as shown in Figure[x].
%
%As a result, particles are only approaching their original trajectories without ever reaching it.
%
%This produces a small delay between a particle and its trajectory but since the magnitude of a single displacement is proportional to the distance of a particle and its trajectory, this delay does not accumulate and remain constant over time.
%
% and its current position and the destination point sa
%
%the next destination currently sampled from the trajectory data
%
%of a particle and its position currently sampled from the trajectory data.
%
%to the destination point and an arbitrary defined speed reduction factor.
%
%This will results in a small delay between a particle and its orginial trajectory.
%Therefore the delay
%
%The magnitude of the displacement is proportional to the distance to the destination point and an arbitrary defined speed reduction factor.
%
%Rather than leaping straight to the next position we perform a displacement in the direction of the actual sampled position but we reduce the magnitude proportionally to an arbitrary speed reduction factor.
%
%The resulting motion is thus smoother as particles browse smaller distances while remaining in the vicinity of their original trajectories.
%
% a delay between the current position of a particle and the next position sampled from the dataset.
%
%Rather than leaping straight to the next position we perform a displacement in the direction of the actual sampled position but we reduce the magnitude proportionally to an arbitrary speed reduction factor.
%
%Consequently, individual particle browse less distance,  while remaining in the vicinity of their original trajectories.
%
%And since their speed is reduced it also possible to keep track 
%
% it might even be impossible 
%
%By reducing the number of 
%
%Reducing the number of displayed frame thus reduce the overall viewing duration for the entire simulation.
%
%Consequently, as many trajectory step are omited,  individual 
%
%%Initially we must produce a simulation data with a very high temporal resolution in order to 
%
%Observing an entire biochemical process can therefore lead to overly long visualization sequences
%
%However, due to the time scale discrepancies between individual reaction and simulated systems, the viewing of the entire simulation at the
%
%
%is able to produce trajectory data as well as reaction history.
%
%represents individual actors of 
%
%For experts not people.
%
%there is still left to address 
%
%cluttered too much thing going one plus problem with mutiple temporal scales.
%
% such as occlusion management for dense scenes or the issues that are due to time-scale discrepancies between entire processes and individual reactions, and which is described as follows:
%
%On the one hand, observing the particle-based simulation at a slow pace to be able to keep track of individual elements and see interactions would require hours to explore the entire process.
%On the other hand, observing the simulation in fast-forward would shorten the viewing length but it would become impossible to observe important reaction events because of the fast pace at which elements would be moving.
%
%Time steps are much larger, which allow 
%
%an entire reaction 
%
%model the entire reaction network of a reaction network and also 
%
%While this modeling approach is not designed to incorporate dynamic information, it was de
%
%These models are a static representation and only constitute a single snap-shot in the multitude of possible states.
%
% modeling entire animated structures would however be  very challenging with this approach
%
%The task of baking and animated sequence would 
%
%the means to model the structures of very large 
%
%Multiscale molecular datasets available form the 
%
%The machinery




%
%\section{Section 4}
%
%So what, our vision is still not done.
%
%We have large structures but cannot render then quickly enough.
%Crucial to be quick.



%so that a single initial per-vertex program 
%is designed to render an entire curve segment.
%The proposed modeling approach aims at provide a representation which resemble
% is designed for efficient real-time rendering and therefore we 
% and it only aims at showing a structure that closely resemble the DNA rather than a stricly accurar
%goal is to depict a close repesentaion of the DNA rather than a scie
%does not depict a scientifically accurate representation of DNA structure
%With their method they are able to render entire amino-acid for a single initial per-vertex operation.
%With most The modeling of DNA fibre structure is 
% to be stored on the memory of graphics devices, for DNA strands are usually composed of very large number of individual bases.
% since the memory transfer between
%would much bigger because of the overly large number of individual  DNA strand.
%(Give example with micoplasma, and E.Coli)
% is two issues that would occur.
%But because of a very large number of individual nucleic acids the resu memory footprint 
%An approach similar to Lampe et al.[] could also be e
%Using this approach 
%We adapted a HiZ buffer culling approach but 
%In order to 
%
%*************************************************
%perform a series of look-up in the HiZ buffer and compare the depth values.
%To minimize the number of look-up the que
%They use a bounding
%To lower the cost of the occlusion culling process they reduce the bounding
%, a bounding volume is often used instead of the entire geometry.
%Upon rendering of the bounding object the resulting depth in the fragment program are then compared with the input depth occlusion texture 
%and if the fragments are deeper that those of the look-up texture this means that the object is hidden.
%Depending on the size of an object, the optimum resolution image will be used for the query to limit the number of read accesses.
%Grottel et al.[] presented an occlusion culli
% hidden molecules will not be processed and create overlap with visible geometries.
%For a given pixel this will results in
%This results in 
%The main bottleneck of this pipeline is located in the per fragment processing at the final stage of the rendering.
%The bottleneck of this pipeline is situated  
% with up to several billions atoms 
% the large quantities of spheres to render will cause 
%The bottleneck of our rendering approach is tied the large quantity of overlapping geometries that are renderer.
%An efficient way to reduce this computational load is to ensure that hidden molecules will not be processed and create overlap with visible geometries.
%Grottel et al uniform particiotning, but limited to finite spaces
%The rendering approach which me present relies to the 
%accumulated GPU-driver
%also causing a GPU-driver overhead for
%after a certain latency which is due to the processing in the graphics pipeline
%The queries are performed in serials which also causes a certain latency due the read-back
%The query resu
%an be read back to the application after a certain latency which is due to the processing in the graphics pipeline
%This method performs 
%against the depth buffer
%that internally implements occlusion culling.

%
%
%\textbf{Occlusion culling.}
%
%Fiber support
%
%These supporting structures are precomputed 
%  of protein structures rather than raw atomic.
%
% and may also occupy more memory space than the raw data
%
%other parts of the pipeline such as the simulation
%
%For far these
%
%the minimum requirement for a comfortable user experience is between 24 and 60 Hz on average for games, and is even higher than 60 Hz for VR content.
%
%, which is still out of reach for very
%
%
%, which additionally leaves little to no room for other type of computation such as animation or physics simulations.

%However, the minimum requirement for a comfortable user experience is between 20 and 60 Hz on average for games, and higher than 60 Hz for VR content, which is still out of reach for very large datasets as the state-of-the-art method is capable of rendering 10 billions atom at 4 fps, which additionally leaves little to no room for other type of computation such as animation or physics simulations.
%
%Moreover, the presented solutions were specifically designed for efficient rendering of proteins data only.
%None of the techniques mentioned above have proved to efficiently support other types of molecular structures that exhibit much more complex organization, such as lipid membranes, nucleic acids or fibers, which ought to be taken into account for a truer depiction of molecular landscapes.
%Indeed, the properties of these structures can represent a challenge, especially for dynamic data because the assembling blocks of these structures are considerably smaller and also more numerous than with protein data.
%Several work focus on the modelling and visualization of such structures, such as life explorer[] or lipid wrapper[].
%However, none of these tools feature a visualization method that has the ambition to support overwhelmingly large datasets such as entire cells and which we deem crucial to achieve interactive and explanatory visualization of molecular biology.
%Furthermore, macro-molecular elements are usually densely arranged inside compartments (see figure), which may results in serious occlusion problems when interactively exploring a dataset.
%This visualization challenge has not yet been explored in the context of molecular visualization although it is crucial to address it to improve the quality of the user experience.
%It is also important to mention that none of the presented method above has been integrated into an animation or game creation package, which makes impossible for content creators to use it is a practical scenario.
%This review of the literature clearly underlines the lack of an efficient and integrated solution that would:
%a) Allow real-time rendering of datasets up to the size of a single cell
%b) Support all type of molecular structures efficiently
%c) Implement efficient occlusion management
%d) Provide tools that are embedded with animation or game creation package for optimized collaboration with various actors of the illustration process.





%\section{Related Work}
%
%Our goal is to improve visual communication of molecular biology, and ultimately to promote interactive showcasing as a standard media for educating the masses about biology.
%Valuable data from computation biology is constantly produced by experts and is often publicly available. 
%It contains thorough description about how things look (structures) and how things work (processes), and we intend to make extensive use of this data to enable the next generation of scientific illustration.
%The visualization literature already comprises a few work that are going in a similar direction and we will distinguish between the related work related to structural visualization in the first section and follow-up with related work about visualization of biochemical processes.

%\textbf{Structures}
%
%Structural biology is the branch of molecular biology that focuses on studying the structure of macromolecular elements in order to better understand their function.
%Visualization is an important component of this discipline because atoms are arranged and assembled in 3 dimensional space and therefore a visual representation is very often required.
%Scientist are using different types of representation to illustrate molecular structures, and we will describe the most commonly used ones.
%The simplest representation is the sticks model, where each bonds are represented as a line and color coding is used to indicate the atom type at the line extremities or joints.
%A popular representation among structural biologists is the secondary structure or ribbon diagram, it is used to reveal properties of the proteins backbone such as sheets or helices.
%The molecular surface representation is used to show a continuous surface that closely surround atoms of a protein and that also close small holes between atoms that are not accessible by small solvent molecules.
%This method was first introduced to reveal information that is not salient enough with other types of representation, such as the presence of pockets and cavities buried in the protein structure and that can potentially host important reaction sites.
%In popular molecular visualization packages such as VMD[] or PyMol[], molecular surfaces are stored as polygon meshes, for the simple reason that meshes are widely supported by graphics APIs.
%Another representation which is commonly understood by a larger audience is the Van der Waals surface, which simply represent atoms as spheres whose radius corresponds to the atomic radius.
%Compared to molecular surfaces, the Van der Waals representation provides important information about atomic composition of proteins which is not clearly visible with molecular surfaces.
%The Van-der-Waals surfaces are usually represented as meshes, but because the surface features highly detailed asperities it often requires a high polygon count to obtain a decent mesh quality, and which may overload the rendering pipeline when a large number of proteins is displayed.
%Molecular surfaces are therefore a commonly used representation among illustrators for depicting large and complex scenes because they can easily import and render meshes with 3D animation packages, and also because surfaces meshes are more lightweight than Van der Waals meshes.
%BioBlender[], Molecular Maya[], ePMV[], are examples of plugins for animation packages that were specifically developed to ease the loading and rendering of molecular surface meshes.
%To improve rendering performances of highly detailed molecular structures, Tarini et al. introduced a novel visualization technique to render Van der Waals surfaces with a much lower polygon count than with surface meshes.
%
%
%
%The rendering method is inspired from 2D billboards, a concept commonly used in computer graphics and games, and consists of drawing camera-facing 2D sphere impostors rather than tessellated 3D spheres when rendering individual atoms, thus considerably reducing the polygon count.
%With their approach, they were able to interactively render large datasets (up to xxxk atoms) with very high quality details.
%This method inspired several follow-up works that address the challenge of the constantly increasing size of available datasets in molecular biology.
%Lampe et al. [8] pioneered real-time rendering of large-scale atomic data on consumer level hardware. 
%They extended the fast billboard-based approach introduced by Tarini et al. [19] by leveraging the geometry shader to instantiate entire atom-blocks rather than single atom, thus reducing the memory bandwidth usage and GPU driver overhead by invoking fewer draw operations. 
%Grottel at al. proposed to improve the rendering speed of large particle-based datasets by implementing occlusion culling to discard hidden particle chunks from the rendering pipeline, based on the depth information obtained in the previous frame.
%Lindow et al. [11] followed-up the work of Lampe et al. by using instanced rendering of entire protein structures instead. 
%For each molecule type, they precompute a 3D grid containing the atomic structure and which is stored on the GPU.
%Upon the drawing of a protein the bounding box is drawn first, then during the per-fragment operation rays are cast through the grid, in order to find the first atom which is hit by the ray.
%Falk et al. [3] further refined the method by introducing depth culling and level-of-detail for the grid structures to achieve faster rendering performance for even larger scenes.
%Up to this point, the rendering methods presented in the literature have reached unprecedented levels of performance, in terms of size of supported dataset and rendering speed.
%However, the minimum requirement for a comfortable user experience is between 20 and 60 Hz on average games, and higher than 60 Hz for VR content, which is still out of reach for very large datasets (10 billions atoms at 4 fps).
%Moreover, the presented solutions were specifically designed for efficient rendering of macro molecules only, such as proteins.
%None of the techniques mentioned above have proved to efficiently support other types of molecular structures that exhibit much more complex organization, such as lipid membranes, nucleic acids or fibers, which ought to be taken into account for a truer depiction of molecular landscapes.
%Indeed, the properties of these structures can represent a challenge, especially for dynamic data because the assembling blocks or these structures are considerably smaller and also more numerous than with protein data.
%Several work focus on the modelling and visualization of such structures, life explorer [] is a visualization software designed for interactive modelling and viewing of DNA strands, lipid wrapper[] is a tool designed to generate lipid membranes based on arbitrary meshes.
%However, none of these tools feature a visualization method that has the ambition to support overwhelmingly large datasets such as entire cells and which we deem crucial to achieve interactive and explanatory visualization of molecular biology.
%
%Moreover, macro-molecular elements are usually densely arranged inside compartments (see figure), which may results in serious occlusion problems when interactively exploring a dataset.
%This visualization challenge has not yet been explored in the context of molecular visualization although it is crucial to address it to improve the quality of the user experience.
%
%This review of the literature clearly underlines the lack of an efficient and integrated solution that would:
%a) Allow real-time rendering of datasets up to the size of a single cell
%b) Support all type of molecular structures efficiently
%c) Implement efficient occlusion management
%d) Provide tools that are embedded with animation or game creation package for optimized collaboration with various actors of the illustration process.

%----------------------
%Several molecular surface computation techniques have been developed, each one with their own drawbacks and advantages.
%SAS[] and Gaussian[] are easy to compute but offer less informative details.
%SES[] and MSS[] are more complex to compute and also provide more surface details which can facilitate the cavity and pocket exploration.
%----------------------

%\textit{and also because smooth surfaces have a much lower overhead than highly tessellated Van-der-Waals surfaces}
%While meshes are often used because of practical reason, they also have a significant computational overhead when featuring a high level of asperity details such as with SES or Van-der-Walls because of the large number of polygon needed to smoothly discretize a complex surface.
%In the visualization literature it exists a few techniques that were developed to overcome this limitation by using a ray-casting approach and grid-based supporting structures.
%Since the recent democratization of domestic and massively parallel computing processors (GPU) it has been possible to implement efficient SES computing and rendering methods [LBPH10,KGE11].
%These methods are able to render the SES for dynamic data sets of around 100k atoms interactively on current hardware.
%Subsequently, Krone et al. implemented a method allowing smooth rendering of Gaussian surfaces for large and dynamic molecular data based on a massively parallel GPU algorithm. 
%%Atoms are stored in a 3D grid, which allows fast accumulation of Gaussian density for each voxel.
%While their technique only supports Gaussian surfaces, which offer less details than SES, they are also able to render much larger dynamic datasets composed of several million atoms.
%Based on the idea that highly detailed molecular surfaces are only needed when closely observing a protein, Parulek et al. introduced the concept of continuous level-of-detail for molecular surfaces.
%They seamlessly transit from highly detailed (SES) to less detailed (Gaussian) surface rendering based on the distance to the camera.
%Because the most complex operation is only performed for a small region of the overall protein, this method provides faster rendering speeds while also reducing visual complexity caused by unnecessary surface details, in the context area.

%The trend in recent molecular surface visualization methods clearly leans towards faster and highly optimized GPU implementations.
%The supporting structures are three dimensional grids because operations performed on such structures can be easily parallelized, thus more efficient.
%The use of uniform spatial partitioning schemes however limits the overall size of the scene, as the complexity and memory usage increases exponentially as the resolution of 3D grid increases, which is why such techniques were not implemented in 3D animation packages and employed by scientific illustrators.
%To overcome this size limitation of the scene, De Hera Chomski[] implemented a CPU-based ray tracing software based on a bounding volume hierarchy (BVH) instead.
%The use of such acceleration structure enable real-time rendering of large and complex scenes, however dynamic data requires constant update of the BVH which adds additional complex work on top of the rendering and limits the real-time capability of the method.

% which is why illustrators often use smooth and simpler surface representations such as the Gaussian instead.

%\textbf{Processes}

%Modeling systems biology processes 
% calls for efficient visualization methods to cope with the complexity nature of the data resulting from the simulation.

%The principle of systems biology is to reproduce complex physiological processes \textit{in silico} in order to better understand how living organisms work.
%Firstly, the models are designed throughout descriptions of molecular interactions that are laid down in 2D reaction networks and digitalized.
%Subsequently, the models are used as input for computational simulations and finally, simulation results are used for further analysis and hypothesis verification.
%It exists a few popular visualization software that aim at connecting the modeling, simulation, and data analysis in a single framework to facilitate the task of biologists, such as CellDesigner[] TinkerCell[] or VCell[].
%These tools usually cover non-spatial models (kinetic modelling), except VCell which also supports the use of external particle-based simulation modules such as Smoldyn[].
%Although the simulation data may feature 3D particle trajectories, the framework do not include a visualization module for observing the behaviour of individual 3D particles, simply because it would have only very little value to most experts as they are more interested in studying changes in species concentration.
%However, in few specific cases, such as the study of signalling pathways for example, the 3D visualization of particle-based simulation results is thought to be informative to scientists that are interested in studying the spatial distribution of certain species over time.
%To a certain extent, this information could also have an informative value for the laymen because it depicts complex processes in the form of a 3D animation, similarly to an explanatory movie.
%Specific visualization tools where developed to produce 3D animations out of such particle-based simulations, supporting either playback of pre-computed data [CellBlender][Falk] or in-situ visualization of simulation computed in real-time [ZigCell].
%Naive visualization of the raw trajectory data, however, may results in an overly cluttered view due to the large number of elements moving in random directions, and it is therefore crucial to intuitively guide the viewer to ensure a maximum degree of clarity.
%Falk et al.[] added to the raw visualization the possibility to track single elements throughout time by tracing the trajectory of a particle and highlight the cascade of reactions which is relevant for the study of signalling pathways.
%Although previous works attempted to improve the raw visualization of particle-based simulation with useful overlaid information, there is still left to address the grand challenge which is due to time-scale discrepancies between entire processes and individual reactions, and which is described as follows: 
%On the one hand, observing the particle-based simulation at a slow pace to be able to keep track of individual elements and see interactions, would require hours to explore the entire process.
%On the other hand, observing the simulation in fast-forward would shorten the viewing length but it would become impossible to observe important reaction events because of the very fast pace at which elements would be moving.
%Furthermore, the real-time limitations of particle-based simulation tools still has to be addressed in order to deliver a smooth educational user experience.
%Indeed, the simulation of particle-based systems is very demanding in terms of computation and is usually precomputed prior to the visualization, which prohibit online interaction with the simulation parameters and real-time exploration of multiple simulation scenario.
%The most-optimized simulation tools leverage the power of GPU computing to speed-up the computation and enable \textit{in-situ} visualization [ZigCell].
%However, even most optimized particle-based simulation methods are still not able to compute complex models in a reasonable amount of time to enable a smooth and interactive experience.
%Other modeling methods, such as kinetic modeling, do not feature 3D dimensional data but are much faster to compute, and therefore quantitative information could also be used to interactively drive 3D animated particle data for explanatory purposes.

%***********************************************************
%Say that the next step-up in scientific illustration is interaction/real-time graphics.
%
%Talk about the currently existing interactive things (Games, tools, installation, VR/AR).
%
%Talk about the importance of interactivity (Faster content creation, non deterministic story telling).
%
%Talk about the limitation is terms of time needed for asset creation.
%
%Talk about the vision, which is an interactive platform that would utilize the data available to  
%***************************************************************


%-----------------------------------------------

%\textbf{Towards a dynamic and interactive model of a cell (E.Coli)}
%
%\textbf{Requirement analysis}
%
%The heart of this thesis is joining together structural and functional data, and the introduction of interactive techniques for the production of biological illustrations.
%
%We see the introduction of interactive illustration as two fold:
%
%.Gain time in producing illustration (render/animation times)
%.Offer a more engaging user experience (multiple scenario exploration VR)
%
%%Dealing with mutliple local scales
%The challenge in rendering lies in rendering multiple scales when dealing with atomic level data.
%
%%Dealing with mutliple temporal scales
%The challenge in animation lies in how to simultaneously show processes operation at different time scales.
%
%%Dealing with interaction and scenario changes
%The challenge in interaction lies in the fact that simulation of spatial data is very slow
%
%%Dealing with occlusion
%Large amount of data which need to be rendering when observing data o

%-----------------------------------------------

%Illustration help to understand but they are time consuming (gathering data, and realization).
%
%Computer graphics programs already help illustrators to accelerate their work (Maya, Cinema4D)
%
%But there is still a lot of work to do.
%
%Constant improvement in game technologies in often applied across field to accelerate the artists job in the movie industry (real-time simulation, real-time rendering, interaction)
%
%This help scientific illustrators too, but often they are using dedicated tools which are not mainstream and therefore only very few process is made for them.
% 
%Structure:
%
%Dealing with Large Amount of Data 
%
%Dealing with Multiple Scales.
%
%Dealing with Stochasticity / Introducing interaction
%
%Dealing with Occlusion.

%Part C the visualization (occlusion)
%Part E spatial navigation 
%Part F temporal navigation 
%Part D scenario interaction 

%\section{Using Computation Data for Storytelling}
%
%\section{Efficient Rendering of Large Structures}
%
%\section{Efficient Spatial Composition and Occlusion Management}
%
%\section{Conclusion}

%Since \LaTeX\ is widely used in academia and industry, there exists a plethora of freely accessible introductions to the language.
%Reading through the guide at \url{https://en.wikibooks.org/wiki/LaTeX} serves as a comprehensive overview for most of the functionality and is highly recommended before starting with a thesis in \LaTeX.
%
%\section{Installation}
%
%A full \LaTeX\ distribution\index{distribution} consists of not only of the binaries that convert the source files to the typeset documents, but also of a wide range of packages and their documentation.
%Depending on the operating system, different implementations are available as shown in Table~\ref{tab:distrib}.
%\textbf{Due to the large amount of packages that are in everyday use and due to their high interdependence, it is paramount to keep the installed distribution\index{distribution} up to date.}
%Otherwise, obscure errors and tedious debugging ensue.
%
%\section{Editors}
%
%A multitude of \TeX\ \glspl{texteditor} are available differing in their editing models, their supported operating systems and their feature sets.
%A comprehensive overview of \glspl{texteditor} can be found at the Wikipedia page  \url{https://en.wikipedia.org/wiki/Comparison_of_TeX_editors}.
%TeXstudio (\url{http://texstudio.sourceforge.net/}) is recommended.
%
%\section{Compilation}
%
%Modern editors usually provide the compilation programs to generate \gls{pdf} documents and for most \LaTeX\ source files, this is sufficient.
%More advanced \LaTeX\ functionality, such as glossaries and bibliographies, needs additional compilation steps, however.
%It is also possible that errors in the compilation process invalidate intermediate files and force subsequent compilation runs to fail.
%It is advisable to delete intermediate files (\verb|.aux|, \verb|.bbl|, etc.), if errors occur and persist.
%All files that are not generated by the user are automatically regenerated.
%To compile the current document, the steps as shown in Table~\ref{tab:compile} have to be taken.